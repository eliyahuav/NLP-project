{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***תרגיל 6 של הפרוייקט***"
      ],
      "metadata": {
        "id": "BWDmLmxFJX1B"
      },
      "id": "BWDmLmxFJX1B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup & Install (Colab)**"
      ],
      "metadata": {
        "id": "h8wNbiD5cRou"
      },
      "id": "h8wNbiD5cRou"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 1 — Setup & Install (Colab)\n",
        "# ============================================================\n",
        "!pip -q install transformers datasets accelerate scikit-learn\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AdamW,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "# Make plots appear in notebook\n",
        "# %matplotlib inline\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "CvwC7zZgb3V2",
        "outputId": "ccfc76df-7b0d-4bf2-a2d3-1b3bc92844ae"
      },
      "id": "CvwC7zZgb3V2",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'AdamW' from 'transformers' (/usr/local/lib/python3.12/dist-packages/transformers/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-515994734.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m from transformers import (\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'AdamW' from 'transformers' (/usr/local/lib/python3.12/dist-packages/transformers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reproducibility (Seeds)**"
      ],
      "metadata": {
        "id": "Ej2-eVH7cUq0"
      },
      "id": "Ej2-eVH7cUq0"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 2 — Reproducibility (Seeds)\n",
        "# ============================================================\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "TkmvAc_-b9i6"
      },
      "id": "TkmvAc_-b9i6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Config (Paths, Labels, Hyperparams)**"
      ],
      "metadata": {
        "id": "BNWLB8UEcWBz"
      },
      "id": "BNWLB8UEcWBz"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 3 — Config (Paths, Labels, Hyperparams)\n",
        "# ============================================================\n",
        "# Path to your CSV (upload it to Colab or mount Google Drive)\n",
        "CSV_PATH = \"/content/train-filtered_question_level.csv\"  # <-- change if needed\n",
        "\n",
        "# Labels mapping (must match your project definition)\n",
        "label2id = {\"easy\": 0, \"medium\": 1, \"hard\": 2}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "NUM_LABELS = 3\n",
        "\n",
        "# According to your dataset analysis:\n",
        "# 95th percentile max length = 44 tokens\n",
        "MAX_LEN = 44\n",
        "\n",
        "# Baseline training hyperparams (you can change later for tuning runs)\n",
        "BASE_LR = 3e-5\n",
        "BASE_BATCH_SIZE = 16\n",
        "BASE_EPOCHS = 3\n",
        "WEIGHT_DECAY = 0.01\n",
        "WARMUP_RATIO = 0.1  # warmup steps = 10% of total steps\n"
      ],
      "metadata": {
        "id": "lCzXeYvVb_Dv"
      },
      "id": "lCzXeYvVb_Dv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset (CSV) + Minimal Cleaning**"
      ],
      "metadata": {
        "id": "SOvb6N2gcZM5"
      },
      "id": "SOvb6N2gcZM5"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 4 — Load Dataset (CSV) + Minimal Cleaning\n",
        "# ============================================================\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    raise FileNotFoundError(f\"CSV not found at: {CSV_PATH}\")\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Expected columns: question, level\n",
        "required_cols = {\"question\", \"level\"}\n",
        "if not required_cols.issubset(set(df.columns)):\n",
        "    raise ValueError(f\"CSV must contain columns: {required_cols}. Found: {df.columns}\")\n",
        "\n",
        "# Minimal safety cleanup (keep it simple; in Transformer stage we avoid heavy preprocessing)\n",
        "df[\"question\"] = df[\"question\"].astype(str)\n",
        "df[\"level\"] = df[\"level\"].astype(str)\n",
        "\n",
        "# Remove exact duplicates by question (if not already done)\n",
        "df = df.drop_duplicates(subset=[\"question\"]).reset_index(drop=True)\n",
        "\n",
        "# Keep only the 3 known labels\n",
        "df = df[df[\"level\"].isin(label2id.keys())].reset_index(drop=True)\n",
        "\n",
        "print(\"Dataset size:\", len(df))\n",
        "print(df[\"level\"].value_counts())\n"
      ],
      "metadata": {
        "id": "L79BYeCicAYb"
      },
      "id": "L79BYeCicAYb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 4.5 — Balance Dataset (7000 per label) + Shuffle\n",
        "# Insert between Block 4 and Block 5\n",
        "# ============================================================\n",
        "\n",
        "SAMPLES_PER_CLASS = 7000\n",
        "\n",
        "# Sanity check: make sure each label has at least 7000 samples\n",
        "counts = df[\"level\"].value_counts()\n",
        "missing = [lbl for lbl in label2id.keys() if counts.get(lbl, 0) < SAMPLES_PER_CLASS]\n",
        "if missing:\n",
        "    raise ValueError(\n",
        "        f\"Not enough samples for labels: {missing}. \"\n",
        "        f\"Counts: {counts.to_dict()}\"\n",
        "    )\n",
        "\n",
        "# Undersample each class to exactly 7000\n",
        "balanced_df = (\n",
        "    df.groupby(\"level\", group_keys=False)\n",
        "      .apply(lambda g: g.sample(n=SAMPLES_PER_CLASS, random_state=42))\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# Full shuffle after balancing (important)\n",
        "balanced_df = balanced_df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df = balanced_df  # overwrite df so the next blocks use the balanced dataset\n",
        "\n",
        "print(\"Balanced dataset size:\", len(df))\n",
        "print(df[\"level\"].value_counts())\n"
      ],
      "metadata": {
        "id": "-FYl2b13e-_H"
      },
      "id": "-FYl2b13e-_H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stratified Split (Train / Val / Test)**"
      ],
      "metadata": {
        "id": "-YPtv_dTccMV"
      },
      "id": "-YPtv_dTccMV"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 5 — Stratified Split (Train / Val / Test)\n",
        "# ============================================================\n",
        "# 70% train, 15% val, 15% test\n",
        "train_df, temp_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.30,\n",
        "    random_state=42,\n",
        "    stratify=df[\"level\"]\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.50,\n",
        "    random_state=42,\n",
        "    stratify=temp_df[\"level\"]\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))\n",
        "print(\"Test distribution:\\n\", test_df[\"level\"].value_counts())\n"
      ],
      "metadata": {
        "id": "ZWMxtuuFcBzb"
      },
      "id": "ZWMxtuuFcBzb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PyTorch Dataset (Tokenizer-based)**"
      ],
      "metadata": {
        "id": "JGFIo_OJceej"
      },
      "id": "JGFIo_OJceej"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 6 — PyTorch Dataset (Tokenizer-based)\n",
        "# ============================================================\n",
        "class TriviaDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    A simple dataset wrapper that tokenizes each question using the model tokenizer.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe: pd.DataFrame, tokenizer, max_len: int):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
        "        text = self.df.loc[idx, \"question\"]\n",
        "        label_str = self.df.loc[idx, \"level\"]\n",
        "        label_id = label2id[label_str]\n",
        "\n",
        "        # Tokenizer creates input_ids + attention_mask (+ token_type_ids for some models)\n",
        "        encoded = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",       # explicit padding\n",
        "            truncation=True,            # explicit truncation\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label_id, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "        # Some models return token_type_ids (BERT); DistilBERT usually does not use it\n",
        "        if \"token_type_ids\" in encoded:\n",
        "            item[\"token_type_ids\"] = encoded[\"token_type_ids\"].squeeze(0)\n",
        "\n",
        "        return item\n"
      ],
      "metadata": {
        "id": "78iImGWocDRj"
      },
      "id": "78iImGWocDRj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Utilities (Accuracy, Loops, Plots)**"
      ],
      "metadata": {
        "id": "vRvS6KAHchh9"
      },
      "id": "vRvS6KAHchh9"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 7 — Training Utilities (Accuracy, Loops, Plots)\n",
        "# ============================================================\n",
        "def batch_accuracy(logits: torch.Tensor, labels: torch.Tensor) -> float:\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    correct = (preds == labels).sum().item()\n",
        "    return correct / labels.size(0)\n",
        "\n",
        "@dataclass\n",
        "class TrainHistory:\n",
        "    train_loss: List[float]\n",
        "    val_loss: List[float]\n",
        "    train_acc: List[float]\n",
        "    val_acc: List[float]\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, scheduler) -> Tuple[float, float]:\n",
        "    model.train()\n",
        "    total_loss, total_acc, n_batches = 0.0, 0.0, 0\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += batch_accuracy(logits, batch[\"labels\"])\n",
        "        n_batches += 1\n",
        "\n",
        "    return total_loss / n_batches, total_acc / n_batches\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, loader) -> Tuple[float, float]:\n",
        "    model.eval()\n",
        "    total_loss, total_acc, n_batches = 0.0, 0.0, 0\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += batch_accuracy(logits, batch[\"labels\"])\n",
        "        n_batches += 1\n",
        "\n",
        "    return total_loss / n_batches, total_acc / n_batches\n",
        "\n",
        "def plot_history(history: TrainHistory, title: str) -> None:\n",
        "    epochs = range(1, len(history.train_loss) + 1)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, history.train_loss, label=\"train_loss\")\n",
        "    plt.plot(epochs, history.val_loss, label=\"val_loss\")\n",
        "    plt.title(title + \" — Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, history.train_acc, label=\"train_acc\")\n",
        "    plt.plot(epochs, history.val_acc, label=\"val_acc\")\n",
        "    plt.title(title + \" — Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ZxYGQymWcFgd"
      },
      "id": "ZxYGQymWcFgd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Utilities (Report + Confusion Matrix)**"
      ],
      "metadata": {
        "id": "kq3AzIkOckyA"
      },
      "id": "kq3AzIkOckyA"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 8 — Evaluation Utilities (Report + Confusion Matrix)\n",
        "# ============================================================\n",
        "@torch.no_grad()\n",
        "def predict(model, loader) -> Tuple[List[int], List[int]]:\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for batch in loader:\n",
        "        labels = batch[\"labels\"].numpy().tolist()\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "        outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy().tolist()\n",
        "\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "    return all_preds, all_labels\n",
        "\n",
        "def show_metrics(y_true: List[int], y_pred: List[int], title: str) -> None:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(title)\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[id2label[i] for i in range(NUM_LABELS)],\n",
        "        digits=4\n",
        "    ))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
        "    print(cm)\n"
      ],
      "metadata": {
        "id": "nqO46K4RcHHJ"
      },
      "id": "nqO46K4RcHHJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Experiment Runner (Model + Tokenizer + Fine-Tuning)**"
      ],
      "metadata": {
        "id": "4VR5VyqscnWA"
      },
      "id": "4VR5VyqscnWA"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 9 — One Experiment Runner (Model + Tokenizer + Fine-Tuning)\n",
        "# ============================================================\n",
        "def run_experiment(\n",
        "    model_name: str,\n",
        "    run_name: str,\n",
        "    lr: float = BASE_LR,\n",
        "    batch_size: int = BASE_BATCH_SIZE,\n",
        "    epochs: int = BASE_EPOCHS\n",
        ") -> Dict:\n",
        "    print(\"\\n\" + \"#\"*80)\n",
        "    print(f\"Running: {run_name}\")\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"LR={lr}, Batch={batch_size}, Epochs={epochs}, MAX_LEN={MAX_LEN}\")\n",
        "    print(\"#\"*80)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    train_ds = TriviaDataset(train_df, tokenizer, MAX_LEN)\n",
        "    val_ds   = TriviaDataset(val_df, tokenizer, MAX_LEN)\n",
        "    test_ds  = TriviaDataset(test_df, tokenizer, MAX_LEN)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    val_loader   = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
        "    test_loader  = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=NUM_LABELS,\n",
        "        label2id=label2id,\n",
        "        id2label=id2label\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    history = TrainHistory(train_loss=[], val_loss=[], train_acc=[], val_acc=[])\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, scheduler)\n",
        "        va_loss, va_acc = eval_one_epoch(model, val_loader)\n",
        "\n",
        "        history.train_loss.append(tr_loss)\n",
        "        history.train_acc.append(tr_acc)\n",
        "        history.val_loss.append(va_loss)\n",
        "        history.val_acc.append(va_acc)\n",
        "\n",
        "        print(f\"Epoch {ep}/{epochs} | train_loss={tr_loss:.4f} train_acc={tr_acc:.4f} | val_loss={va_loss:.4f} val_acc={va_acc:.4f}\")\n",
        "\n",
        "    plot_history(history, title=run_name)\n",
        "\n",
        "    # Final evaluation on TEST\n",
        "    y_pred, y_true = predict(model, test_loader)\n",
        "    show_metrics(y_true, y_pred, title=f\"{run_name} — Test Evaluation\")\n",
        "\n",
        "    return {\n",
        "        \"run_name\": run_name,\n",
        "        \"model_name\": model_name,\n",
        "        \"lr\": lr,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "        \"history\": history,\n",
        "        \"y_true\": y_true,\n",
        "        \"y_pred\": y_pred,\n",
        "        \"model\": model,\n",
        "        \"tokenizer\": tokenizer\n",
        "    }\n"
      ],
      "metadata": {
        "id": "wfYxUJW2cHpd"
      },
      "id": "wfYxUJW2cHpd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Run Stage 1 (Two Models)**"
      ],
      "metadata": {
        "id": "tTads4BScqUe"
      },
      "id": "tTads4BScqUe"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 10 — Run Stage 1 (Two Models)\n",
        "# ============================================================\n",
        "# 1) Small baseline model (works fast)\n",
        "distilbert_result = run_experiment(\n",
        "    model_name=\"distilbert-base-uncased\",\n",
        "    run_name=\"Stage1_DistilBERT_uncased\",\n",
        "    lr=3e-5,\n",
        "    batch_size=16,\n",
        "    epochs=3\n",
        ")\n",
        "\n",
        "# 2) Larger model for comparison (after baseline works)\n",
        "bert_cased_result = run_experiment(\n",
        "    model_name=\"bert-base-cased\",\n",
        "    run_name=\"Stage1_BERT_cased\",\n",
        "    lr=2e-5,          # often a bit safer for larger models; feel free to tune\n",
        "    batch_size=16,\n",
        "    epochs=3\n",
        ")\n"
      ],
      "metadata": {
        "id": "ODLTWBs9cKGF"
      },
      "id": "ODLTWBs9cKGF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quick Side-by-Side Summary (Accuracy Only)**"
      ],
      "metadata": {
        "id": "GZ-gsvTCcs0r"
      },
      "id": "GZ-gsvTCcs0r"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 11 — Quick Side-by-Side Summary (Accuracy Only)\n",
        "# ============================================================\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "distil_acc = accuracy_score(distilbert_result[\"y_true\"], distilbert_result[\"y_pred\"])\n",
        "bert_acc = accuracy_score(bert_cased_result[\"y_true\"], bert_cased_result[\"y_pred\"])\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Stage 1 Summary (Test Accuracy)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"DistilBERT-uncased: {distil_acc:.4f}\")\n",
        "print(f\"BERT-base-cased:    {bert_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "01rHw93DcLU4"
      },
      "id": "01rHw93DcLU4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Block 12 — (Optional) Save Models to Drive / Local\n",
        "# ============================================================\n",
        "# You can save each fine-tuned model for later stages\n",
        "# Example:\n",
        "# distilbert_result[\"model\"].save_pretrained(\"/content/distilbert_stage1\")\n",
        "# distilbert_result[\"tokenizer\"].save_pretrained(\"/content/distilbert_stage1\")\n",
        "#\n",
        "# bert_cased_result[\"model\"].save_pretrained(\"/content/bert_cased_stage1\")\n",
        "# bert_cased_result[\"tokenizer\"].save_pretrained(\"/content/bert_cased_stage1\")\n"
      ],
      "metadata": {
        "id": "IQVwr_i8cMmX"
      },
      "id": "IQVwr_i8cMmX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}