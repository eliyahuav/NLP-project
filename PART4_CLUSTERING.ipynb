{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***תרגיל 4   של הפרוייקט***"
      ],
      "metadata": {
        "id": "BWDmLmxFJX1B"
      },
      "id": "BWDmLmxFJX1B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***א-1***"
      ],
      "metadata": {
        "id": "f_aW02ESJLOo"
      },
      "id": "f_aW02ESJLOo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Load data and basic inspection***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5gm7encWEu_u"
      },
      "id": "5gm7encWEu_u"
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 1: Load data and basic inspection ===\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the filtered dataset from disk (Colab path)\n",
        "filtered_df = pd.read_csv(\"/content/train-filtered_question_level.csv\")\n",
        "\n",
        "# Remove duplicate questions to avoid biasing the model with repeated texts\n",
        "filtered_df = filtered_df.drop_duplicates(subset=[\"question\"], keep=\"first\")\n",
        "\n",
        "# Sanity check: show columns and first rows to verify the structure\n",
        "print(\"Columns in DataFrame:\")\n",
        "print(filtered_df.columns)\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(filtered_df.head())\n",
        "\n",
        "# Show global label distribution for 'level' (if exists), to understand dataset balance\n",
        "if \"level\" in filtered_df.columns:\n",
        "    print(\"\\nGlobal distribution of 'level':\")\n",
        "    print(filtered_df[\"level\"].value_counts(normalize=True))\n",
        "else:\n",
        "    print(\"\\nColumn 'level' not found in DataFrame.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxymC_hSmq8K",
        "outputId": "adeddaf5-a687-4da4-e4da-c0e04fc3f174"
      },
      "id": "sxymC_hSmq8K",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in DataFrame:\n",
            "Index(['question', 'level'], dtype='object')\n",
            "\n",
            "First 5 rows:\n",
            "                                            question   level\n",
            "0  Which magazine was started first Arthur's Maga...  medium\n",
            "1  The Oberoi family is part of a hotel company t...  medium\n",
            "2  Musician and satirist Allie Goertz wrote a son...    hard\n",
            "3    What nationality was James Henry Miller's wife?  medium\n",
            "4  Cadmium Chloride is slightly soluble in this c...  medium\n",
            "\n",
            "Global distribution of 'level':\n",
            "level\n",
            "medium    0.628149\n",
            "easy      0.198688\n",
            "hard      0.173162\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***חלוקה מאוזנת ל־train / validation / test (עם stratify)***"
      ],
      "metadata": {
        "id": "2x9zwKKfpeX-"
      },
      "id": "2x9zwKKfpeX-"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define split proportions\n",
        "# TEST_SIZE = 0.15      # 15% of total data for test\n",
        "# VAL_SIZE = 0.15       # 15% of total data for validation\n",
        "# RANDOM_STATE = 42     # For reproducibility\n",
        "\n",
        "# # Compute validation size relative to the remaining data after test split\n",
        "# val_size_relative = VAL_SIZE / (1 - TEST_SIZE)  # e.g., 0.15 / 0.85\n",
        "\n",
        "# print(\"Relative validation size (from train_val):\", val_size_relative)\n",
        "\n",
        "# # Step 1: Split into train_val and test with stratification on 'level'\n",
        "# train_val_df, test_df = train_test_split(\n",
        "#     filtered_df,\n",
        "#     test_size=TEST_SIZE,\n",
        "#     stratify=filtered_df[\"level\"],\n",
        "#     random_state=RANDOM_STATE\n",
        "# )\n",
        "\n",
        "# # Step 2: Split train_val into train and validation with stratification on 'level'\n",
        "# train_df, val_df = train_test_split(\n",
        "#     train_val_df,\n",
        "#     test_size=val_size_relative,\n",
        "#     stratify=train_val_df[\"level\"],\n",
        "#     random_state=RANDOM_STATE\n",
        "# )\n",
        "\n",
        "# print(\"Finished stratified split into train / validation / test.\")\n"
      ],
      "metadata": {
        "id": "m176qvlxpdZJ"
      },
      "id": "m176qvlxpdZJ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***בדיקה שהחלוקה מאוזנת (stratified) ושיש לנו את היחסים הרצויים***"
      ],
      "metadata": {
        "id": "rpBACoIoplWC"
      },
      "id": "rpBACoIoplWC"
    },
    {
      "cell_type": "code",
      "source": [
        "# def print_split_info(df, name):\n",
        "#     print(f\"\\n{name}:\")\n",
        "#     print(\"Number of rows:\", len(df))\n",
        "#     print(\"Label distribution for 'level':\")\n",
        "#     print(df[\"level\"].value_counts(normalize=True))\n",
        "\n",
        "# print(\"Total rows in original filtered_df:\", len(filtered_df))\n",
        "\n",
        "# print_split_info(train_df, \"Train set\")\n",
        "# print_split_info(val_df, \"Validation set\")\n",
        "# print_split_info(test_df, \"Test set\")\n"
      ],
      "metadata": {
        "id": "pev31-BLplxP"
      },
      "id": "pev31-BLplxP",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KtfJcpMAJofI"
      },
      "id": "KtfJcpMAJofI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Text preprocessing (tokenization + lemmatization)***"
      ],
      "metadata": {
        "id": "zeHPEQzQJsf6"
      },
      "id": "zeHPEQzQJsf6"
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2 (HARD FIX): NLTK setup and robust preprocessing ===\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize, pos_tag\n",
        "\n",
        "# Download required NLTK resources (run once per runtime)\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "eng_stops = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Normalize all forms of the verb \"to be\" into a single token \"be\"\n",
        "BE_FORMS = {\"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\"}\n",
        "\n",
        "\n",
        "def get_wordnet_pos(tag: str):\n",
        "    \"\"\"\n",
        "    Map POS tag from nltk.pos_tag to a WordNet POS tag.\n",
        "    This helps the lemmatizer pick the correct base form.\n",
        "    \"\"\"\n",
        "    if tag.startswith(\"J\"):\n",
        "        return wordnet.ADJ\n",
        "    if tag.startswith(\"V\"):\n",
        "        return wordnet.VERB\n",
        "    if tag.startswith(\"N\"):\n",
        "        return wordnet.NOUN\n",
        "    if tag.startswith(\"R\"):\n",
        "        return wordnet.ADV\n",
        "    return wordnet.NOUN\n",
        "\n",
        "\n",
        "# Regex patterns for cleaning\n",
        "# Remove URLs, emails, @handles, #hashtags\n",
        "url_email_handle_re = re.compile(r\"(https?://\\S+|www\\.\\S+|\\S+@\\S+|[@#]\\w+)\", re.IGNORECASE)\n",
        "\n",
        "# Detect any digit inside a token\n",
        "digits_re = re.compile(r\"\\d\")\n",
        "\n",
        "# For NON-numeric tokens: remove everything except [a-z] and spaces\n",
        "non_letter_re = re.compile(r\"[^a-z ]+\")\n",
        "\n",
        "\n",
        "def process_text_value(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Full preprocessing for a single text value:\n",
        "    - Remove URLs, emails, and @handles/#hashtags\n",
        "    - Tokenize\n",
        "    - POS tagging\n",
        "    - Lemmatization with POS\n",
        "    - Normalize all 'be' verb forms to 'be'\n",
        "    - Any token that contains at least one digit -> '_number' (entire token)\n",
        "    - For other tokens: strip punctuation/non-letters, keep only [a-z] and spaces\n",
        "    - Finally, any token that still contains the substring 'number' is collapsed to '_number'\n",
        "    - (Optional) Remove stopwords [currently commented out]\n",
        "    - Lowercase\n",
        "    Returns a cleaned string with space-separated tokens.\n",
        "    \"\"\"\n",
        "    # Safely handle missing or non-string values\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Remove URLs, emails, handles, hashtags\n",
        "    t = url_email_handle_re.sub(\" \", text)\n",
        "\n",
        "    # Tokenize and POS-tag on original (cleaned) text\n",
        "    tokens = word_tokenize(t)\n",
        "    tagged = pos_tag(tokens)\n",
        "\n",
        "    lemmas = []\n",
        "    for tok, pos in tagged:\n",
        "        # Normalize 'be' forms early to reduce sparsity\n",
        "        if tok.lower() in BE_FORMS:\n",
        "            lemmas.append(\"be\")\n",
        "            continue\n",
        "\n",
        "        # Map POS tag to WordNet POS tag and lemmatize\n",
        "        wn_pos = get_wordnet_pos(pos)\n",
        "        lemma = lemmatizer.lemmatize(tok, wn_pos)\n",
        "        lemmas.append(lemma)\n",
        "\n",
        "    # Lowercase all tokens\n",
        "    lemmas = [w.lower() for w in lemmas]\n",
        "\n",
        "    intermediate = []\n",
        "    for w in lemmas:\n",
        "        # If the token contains ANY digit, replace the entire token with '_number'\n",
        "        if digits_re.search(w):\n",
        "            intermediate.append(\"_number\")\n",
        "            continue\n",
        "\n",
        "        # For non-numeric tokens: remove punctuation and non-letters\n",
        "        w2 = non_letter_re.sub(\" \", w).strip()\n",
        "        if not w2:\n",
        "            # Skip tokens that became empty after cleaning\n",
        "            continue\n",
        "\n",
        "        # If cleaning produced multiple parts (e.g. \"word-word\" -> \"word word\")\n",
        "        for part in w2.split():\n",
        "            if not part:\n",
        "                continue\n",
        "            intermediate.append(part)\n",
        "\n",
        "    # Final pass: collapse any token that still contains 'number' into '_number'\n",
        "    # This guarantees we do not get '_numbera', '_numberkm', etc.\n",
        "    clean_lemmas = []\n",
        "    for w in intermediate:\n",
        "        if \"number\" in w:\n",
        "            clean_lemmas.append(\"_number\")\n",
        "        else:\n",
        "            clean_lemmas.append(w)\n",
        "\n",
        "    # If you want to remove stopwords, uncomment the next line\n",
        "    # clean_lemmas = [w for w in clean_lemmas if w not in eng_stops]\n",
        "\n",
        "    # Join tokens back into a single cleaned string\n",
        "    return \" \".join(clean_lemmas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toAKXIEoMcY3",
        "outputId": "9b9ce538-0f38-41e3-ea45-15d61af3aa4f"
      },
      "id": "toAKXIEoMcY3",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Apply preprocessing to all questions***"
      ],
      "metadata": {
        "id": "qwOP_ovgRKwO"
      },
      "id": "qwOP_ovgRKwO"
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3: Apply preprocessing to all questions ===\n",
        "\n",
        "# Ensure the 'question' column exists before applying preprocessing\n",
        "if \"question\" not in filtered_df.columns:\n",
        "    raise KeyError(\"The DataFrame does not contain a 'question' column.\")\n",
        "\n",
        "# Apply the preprocessing function to every question in the dataset\n",
        "# This creates a new column 'question_clean' that contains the normalized text\n",
        "filtered_df[\"question_clean\"] = filtered_df[\"question\"].apply(process_text_value)\n",
        "\n",
        "# Inspect a few examples to verify that preprocessing works as expected\n",
        "print(\"Original vs. cleaned examples:\\n\")\n",
        "for i in range(5):\n",
        "    print(f\"--- Example {i+1} ---\")\n",
        "    print(\"Original :\", filtered_df.loc[filtered_df.index[i], \"question\"])\n",
        "    print(\"Cleaned  :\", filtered_df.loc[filtered_df.index[i], \"question_clean\"])\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "VPjsviBsQxIg"
      },
      "id": "VPjsviBsQxIg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF vectorization of the preprocessed questions***"
      ],
      "metadata": {
        "id": "ovO3e28_RrXX"
      },
      "id": "ovO3e28_RrXX"
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 4: TF-IDF vectorization for ALL questions (no train/val/test split) ===\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Safety check: make sure 'clean_text' exists\n",
        "if \"clean_text\" not in filtered_df.columns:\n",
        "    raise KeyError(\"The DataFrame does not contain a 'clean_text' column. \"\n",
        "                   \"Run the preprocessing cell first.\")\n",
        "\n",
        "# Define a TF-IDF vectorizer\n",
        "# max_features limits vocabulary size to the most frequent terms\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=10000,   # limit vocabulary size (you can tune this later)\n",
        "    ngram_range=(1, 1),   # unigrams only\n",
        ")\n",
        "\n",
        "# Fit TF-IDF on the entire cleaned corpus and transform it to a sparse matrix\n",
        "# Each row = one question, each column = one term from the vocabulary\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(filtered_df[\"clean_text\"])\n",
        "\n",
        "print(\"TF-IDF matrix shape (n_samples, n_features):\", X_tfidf.shape)\n",
        "print(\"(Num of documents, max_features)\")\n",
        "\n",
        "# Optional: extract labels if you need them later for supervised models / evaluation\n",
        "if \"level\" in filtered_df.columns:\n",
        "    y = filtered_df[\"level\"].values\n",
        "    print(\"Labels vector shape:\", y.shape)\n",
        "else:\n",
        "    y = None\n",
        "    print(\"No 'level' column found. y is set to None.\")\n",
        "\n",
        "# Show a small sample of feature names for sanity check\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "print(\"\\nVocabulary size (len(feature_names)):\", len(feature_names))\n",
        "print(\"First 30 features:\\n\", feature_names[:60])\n"
      ],
      "metadata": {
        "id": "tqDPZN-mRvtC"
      },
      "id": "tqDPZN-mRvtC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Run K-Means for different K values***"
      ],
      "metadata": {
        "id": "EcDOCcPqfNof"
      },
      "id": "EcDOCcPqfNof"
    },
    {
      "cell_type": "code",
      "source": [
        "# # === Cell 5: Run K-Means for several K values ===\n",
        "\n",
        "# from sklearn.cluster import KMeans\n",
        "# from sklearn.metrics import silhouette_score\n",
        "\n",
        "# # Choose several K values (must include 2 and 3 as required)\n",
        "# # k_values = [2, 3, 5, 7, 10, 15]\n",
        "# k_values = [2]\n",
        "# inertia_scores = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# print(\"Running K-Means on TF-IDF matrix... (may take a bit)\")\n",
        "\n",
        "# for k in k_values:\n",
        "#     print(f\"\\n--- K = {k} ---\")\n",
        "\n",
        "#     # KMeans (using smart initialization k-means++)\n",
        "#     kmeans = KMeans(\n",
        "#         n_clusters=k,\n",
        "#         init=\"k-means++\",\n",
        "#         max_iter=300,\n",
        "#         random_state=42,\n",
        "#         n_init=10\n",
        "#     )\n",
        "\n",
        "#     # Fit on full TF-IDF matrix\n",
        "#     kmeans.fit(X_tfidf)\n",
        "\n",
        "#     # Inertia (Elbow)\n",
        "#     inertia = kmeans.inertia_\n",
        "#     inertia_scores.append(inertia)\n",
        "\n",
        "#     # Silhouette score (requires >1 cluster)\n",
        "#     sil_score = silhouette_score(X_tfidf, kmeans.labels_, metric='euclidean')\n",
        "#     silhouette_scores.append(sil_score)\n",
        "\n",
        "#     print(f\"Inertia: {inertia}\")\n",
        "#     print(f\"Silhouette Score: {sil_score}\")\n"
      ],
      "metadata": {
        "id": "maiFWWISfQ8i"
      },
      "id": "maiFWWISfQ8i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Dimensionality reduction for clustering***"
      ],
      "metadata": {
        "id": "aZHPgbrym66T"
      },
      "id": "aZHPgbrym66T"
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 5: Dimensionality reduction for clustering (TruncatedSVD) ===\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# We reduce dimensionality because TF-IDF has many features and is sparse.\n",
        "# TruncatedSVD is PCA-like but works directly on sparse matrices.\n",
        "svd = TruncatedSVD(\n",
        "    n_components=50,   # number of latent dimensions (you can tune this)\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit SVD on the TF-IDF matrix and transform it to a dense lower-dimensional space\n",
        "X_svd = svd.fit_transform(X_tfidf)\n",
        "\n",
        "print(\"Original TF-IDF shape :\", X_tfidf.shape)\n",
        "print(\"Reduced SVD shape     :\", X_svd.shape)\n",
        "\n",
        "# Sum of explained variance ratio gives an idea how much information we kept\n",
        "explained = svd.explained_variance_ratio_.sum()\n",
        "print(f\"Total explained variance (approx): {explained:.3f}\")\n"
      ],
      "metadata": {
        "id": "hARCTg3ilzVP"
      },
      "id": "hARCTg3ilzVP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***DBSCAN clustering on reduced space and comparison***"
      ],
      "metadata": {
        "id": "CaaQVZ42nC-r"
      },
      "id": "CaaQVZ42nC-r"
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 6: DBSCAN clustering on SVD-reduced data ===\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "import numpy as np\n",
        "\n",
        "# Define DBSCAN hyperparameters\n",
        "# eps controls neighborhood radius; min_samples controls how many neighbors define a \"dense\" region\n",
        "dbscan = DBSCAN(\n",
        "    eps=1.0,          # you can tune this (e.g., 0.5, 0.7, 1.2, ...)\n",
        "    min_samples=5,    # minimum number of points to form a dense region\n",
        "    metric=\"euclidean\",\n",
        "    n_jobs=-1         # use all available cores for distance computations\n",
        ")\n",
        "\n",
        "print(\"Fitting DBSCAN on SVD-reduced data (this may take some time)...\")\n",
        "dbscan_labels = dbscan.fit_predict(X_svd)\n",
        "\n",
        "# Count how many points fell into each cluster (including noise = -1)\n",
        "unique_labels, counts = np.unique(dbscan_labels, return_counts=True)\n",
        "label_counts = dict(zip(unique_labels, counts))\n",
        "\n",
        "print(\"\\nCluster label counts (including noise label = -1):\")\n",
        "print(label_counts)\n",
        "\n",
        "# Filter out noise points (-1) before computing Silhouette score\n",
        "mask = dbscan_labels != -1\n",
        "num_clusters = len(set(dbscan_labels[mask]))\n",
        "\n",
        "if num_clusters < 2:\n",
        "    # Silhouette score is not defined if there is fewer than 2 clusters\n",
        "    print(\"\\nDBSCAN found fewer than 2 clusters (after removing noise).\")\n",
        "    print(\"Silhouette score is not defined in this case.\")\n",
        "else:\n",
        "    # Silhouette score on the non-noise points only\n",
        "    dbscan_sil = silhouette_score(X_svd[mask], dbscan_labels[mask])\n",
        "    print(f\"\\nDBSCAN Silhouette Score (on non-noise points): {dbscan_sil:.4f}\")\n",
        "    print(\"\\nYou can compare this value to the Silhouette scores you got from K-Means.\")\n"
      ],
      "metadata": {
        "id": "U7aVlLXJnE4y"
      },
      "id": "U7aVlLXJnE4y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================***"
      ],
      "metadata": {
        "id": "AIYAEt4gYCnL"
      },
      "id": "AIYAEt4gYCnL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Build document vectors from Word2Vec (TF-IDF weighted average)***"
      ],
      "metadata": {
        "id": "5ke7Pi-KUlGD"
      },
      "id": "5ke7Pi-KUlGD"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Build a dictionary: word -> IDF score, based on the TF-IDF vocabulary\n",
        "idf_scores = dict(zip(tfidf_vectorizer.get_feature_names_out(),\n",
        "                      tfidf_vectorizer.idf_))\n",
        "\n",
        "def document_vector(tokens, use_tfidf_weight=True):\n",
        "    \"\"\"\n",
        "    Compute a single document vector from word vectors.\n",
        "    By default uses TF-IDF weights as recommended.\n",
        "    - tokens: list of preprocessed, lemmatized tokens\n",
        "    - use_tfidf_weight: if True, weight each word vector by its IDF\n",
        "    \"\"\"\n",
        "    vectors = []\n",
        "    weights = []\n",
        "\n",
        "    for tok in tokens:\n",
        "        if tok in w2v_model.wv:\n",
        "            vec = w2v_model.wv[tok]\n",
        "            if use_tfidf_weight:\n",
        "                weight = idf_scores.get(tok, 1.0)\n",
        "            else:\n",
        "                weight = 1.0\n",
        "            vectors.append(vec * weight)\n",
        "            weights.append(weight)\n",
        "\n",
        "    if not vectors:\n",
        "        # If no token has a vector, return a zero vector\n",
        "        return np.zeros(w2v_model.vector_size, dtype=np.float32)\n",
        "\n",
        "    vectors = np.vstack(vectors)\n",
        "    weights = np.array(weights, dtype=np.float32)\n",
        "\n",
        "    # Weighted average: sum(w_i * v_i) / sum(w_i)\n",
        "    return vectors.sum(axis=0) / weights.sum()\n",
        "\n",
        "# Build document-level vectors for each split\n",
        "X_train_w2v = np.vstack(train_df[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True)))\n",
        "X_val_w2v   = np.vstack(val_df[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True)))\n",
        "X_test_w2v  = np.vstack(test_df[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True)))\n",
        "\n",
        "print(\"Word2Vec document matrices shapes:\")\n",
        "print(\"X_train_w2v:\", X_train_w2v.shape)\n",
        "print(\"X_val_w2v:  \", X_val_w2v.shape)\n",
        "print(\"X_test_w2v: \", X_test_w2v.shape)\n"
      ],
      "metadata": {
        "id": "ZwRZS0yDUudb"
      },
      "id": "ZwRZS0yDUudb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***ב-1-סיווג בינארי***"
      ],
      "metadata": {
        "id": "2HJK_nb4xcES"
      },
      "id": "2HJK_nb4xcES"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Filter to binary classes (easy, hard)***"
      ],
      "metadata": {
        "id": "AdkAzZ-Q11NJ"
      },
      "id": "AdkAzZ-Q11NJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only 'easy' and 'hard' classes\n",
        "binary_train = train_df[train_df[\"level\"].isin([\"easy\", \"hard\"])].copy()\n",
        "binary_val   = val_df[val_df[\"level\"].isin([\"easy\", \"hard\"])].copy()\n",
        "binary_test  = test_df[test_df[\"level\"].isin([\"easy\", \"hard\"])].copy()\n",
        "\n",
        "print(\"Train size:\", len(binary_train))\n",
        "print(\"Validation size:\", len(binary_val))\n",
        "print(\"Test size:\", len(binary_test))\n",
        "\n",
        "print(\"\\nTrain label distribution:\")\n",
        "print(binary_train[\"level\"].value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "NcjvK2Ndxcf8"
      },
      "id": "NcjvK2Ndxcf8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Encode labels (easy=0, hard=1)***"
      ],
      "metadata": {
        "id": "ZaCcDxS601Pd"
      },
      "id": "ZaCcDxS601Pd"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "y_train = le.fit_transform(binary_train[\"level\"])\n",
        "y_val   = le.transform(binary_val[\"level\"])\n",
        "y_test  = le.transform(binary_test[\"level\"])\n",
        "\n",
        "print(\"Label classes:\", le.classes_)  # ['easy' 'hard']\n"
      ],
      "metadata": {
        "id": "egO2tI2e07eI"
      },
      "id": "egO2tI2e07eI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Build TF-IDF for the binary subsets***"
      ],
      "metadata": {
        "id": "kkibpNFb08Gx"
      },
      "id": "kkibpNFb08Gx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse the same TF-IDF vectorizer that was already fitted on full train_df\n",
        "X_train_tfidf_bin = tfidf_vectorizer.transform(binary_train[\"clean_text\"])\n",
        "X_val_tfidf_bin   = tfidf_vectorizer.transform(binary_val[\"clean_text\"])\n",
        "X_test_tfidf_bin  = tfidf_vectorizer.transform(binary_test[\"clean_text\"])\n",
        "\n",
        "print(\"Binary TF-IDF shapes:\")\n",
        "print(\"X_train_tfidf_bin:\", X_train_tfidf_bin.shape)\n",
        "print(\"X_val_tfidf_bin:  \", X_val_tfidf_bin.shape)\n",
        "print(\"X_test_tfidf_bin: \", X_test_tfidf_bin.shape)\n"
      ],
      "metadata": {
        "id": "O2qL3tCy08wD"
      },
      "id": "O2qL3tCy08wD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Build Word2Vec document vectors for the binary subsets***"
      ],
      "metadata": {
        "id": "6JT2DoNx23au"
      },
      "id": "6JT2DoNx23au"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming you already have w2v_model and document_vector() defined\n",
        "\n",
        "X_train_w2v_bin = np.vstack(\n",
        "    binary_train[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "X_val_w2v_bin = np.vstack(\n",
        "    binary_val[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "X_test_w2v_bin = np.vstack(\n",
        "    binary_test[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "\n",
        "print(\"Binary Word2Vec shapes:\")\n",
        "print(\"X_train_w2v_bin:\", X_train_w2v_bin.shape)\n",
        "print(\"X_val_w2v_bin:  \", X_val_w2v_bin.shape)\n",
        "print(\"X_test_w2v_bin: \", X_test_w2v_bin.shape)\n"
      ],
      "metadata": {
        "id": "YdtdkzqG21nt"
      },
      "id": "YdtdkzqG21nt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Utility: evaluate model***"
      ],
      "metadata": {
        "id": "wgrwWdZi1LvQ"
      },
      "id": "wgrwWdZi1LvQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "def evaluate_model(model_name, representation_name, y_true, y_pred):\n",
        "    print(f\"\\n=== {model_name} + {representation_name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "9DI7lMjR1Q07"
      },
      "id": "9DI7lMjR1Q07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF + Naive Bayes***"
      ],
      "metadata": {
        "id": "ycZgqE4Q1ZIl"
      },
      "id": "ycZgqE4Q1ZIl"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_tfidf = MultinomialNB()\n",
        "nb_tfidf.fit(X_train_tfidf_bin, y_train)\n",
        "\n",
        "pred_val = nb_tfidf.predict(X_val_tfidf_bin)\n",
        "\n",
        "evaluate_model(\"Naive Bayes\", \"TF-IDF\", y_val, pred_val)\n"
      ],
      "metadata": {
        "id": "WN4QUQm11dqL"
      },
      "id": "WN4QUQm11dqL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF + Logistic Regression***"
      ],
      "metadata": {
        "id": "W5XLMNuQ1eFx"
      },
      "id": "W5XLMNuQ1eFx"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_tfidf = LogisticRegression(max_iter=2000)\n",
        "lr_tfidf.fit(X_train_tfidf_bin, y_train)\n",
        "\n",
        "pred_val = lr_tfidf.predict(X_val_tfidf_bin)\n",
        "\n",
        "evaluate_model(\"Logistic Regression\", \"TF-IDF\", y_val, pred_val)\n"
      ],
      "metadata": {
        "id": "6lSuSL5Q1erE"
      },
      "id": "6lSuSL5Q1erE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word2Vec + Naive Bayes***"
      ],
      "metadata": {
        "id": "BDQ-NH5I1fi_"
      },
      "id": "BDQ-NH5I1fi_"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb_w2v = GaussianNB()\n",
        "nb_w2v.fit(X_train_w2v_bin, y_train)\n",
        "\n",
        "pred_val = nb_w2v.predict(X_val_w2v_bin)\n",
        "\n",
        "evaluate_model(\"Naive Bayes (Gaussian)\", \"Word2Vec\", y_val, pred_val)\n"
      ],
      "metadata": {
        "id": "UHl9DRK-1p3W"
      },
      "id": "UHl9DRK-1p3W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word2Vec + Logistic Regression***"
      ],
      "metadata": {
        "id": "iMBIEtHy1roq"
      },
      "id": "iMBIEtHy1roq"
    },
    {
      "cell_type": "code",
      "source": [
        "lr_w2v = LogisticRegression(max_iter=2000)\n",
        "lr_w2v.fit(X_train_w2v_bin, y_train)\n",
        "\n",
        "pred_val = lr_w2v.predict(X_val_w2v_bin)\n",
        "\n",
        "evaluate_model(\"Logistic Regression\", \"Word2Vec\", y_val, pred_val)\n"
      ],
      "metadata": {
        "id": "FT8d4Wnv1ul2"
      },
      "id": "FT8d4Wnv1ul2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***ב-1- סיווג רב מחלקתי כלומר 3***"
      ],
      "metadata": {
        "id": "faKA2iZN5NsH"
      },
      "id": "faKA2iZN5NsH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Build multi-class subsets (easy, medium, hard)***"
      ],
      "metadata": {
        "id": "dpfRTFW25cZ5"
      },
      "id": "dpfRTFW25cZ5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only the three target classes\n",
        "target_levels = [\"easy\", \"medium\", \"hard\"]\n",
        "\n",
        "multi_train = train_df[train_df[\"level\"].isin(target_levels)].copy()\n",
        "multi_val   = val_df[val_df[\"level\"].isin(target_levels)].copy()\n",
        "multi_test  = test_df[test_df[\"level\"].isin(target_levels)].copy()\n",
        "\n",
        "print(\"Train size:\", len(multi_train))\n",
        "print(\"Validation size:\", len(multi_val))\n",
        "print(\"Test size:\", len(multi_test))\n",
        "\n",
        "print(\"\\nTrain label distribution:\")\n",
        "print(multi_train[\"level\"].value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nUnique levels in all splits:\")\n",
        "print(\"Train:\", multi_train[\"level\"].unique())\n",
        "print(\"Val:  \", multi_val[\"level\"].unique())\n",
        "print(\"Test: \", multi_test[\"level\"].unique())\n"
      ],
      "metadata": {
        "id": "GRO-qxBV5c0J"
      },
      "id": "GRO-qxBV5c0J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Encode labels (3 classes)***"
      ],
      "metadata": {
        "id": "5hSpOfJ95ocX"
      },
      "id": "5hSpOfJ95ocX"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le_multi = LabelEncoder()\n",
        "\n",
        "y_train_multi = le_multi.fit_transform(multi_train[\"level\"])\n",
        "y_val_multi   = le_multi.transform(multi_val[\"level\"])\n",
        "y_test_multi  = le_multi.transform(multi_test[\"level\"])\n",
        "\n",
        "print(\"Label classes (order):\", le_multi.classes_)  # expects ['easy' 'hard' 'medium'] or similar\n"
      ],
      "metadata": {
        "id": "u9v-DDlP5owa"
      },
      "id": "u9v-DDlP5owa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF representation for multi-class***"
      ],
      "metadata": {
        "id": "ukMMIGQQ5uQv"
      },
      "id": "ukMMIGQQ5uQv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform clean_text into TF-IDF vectors using the existing fitted vectorizer\n",
        "X_train_tfidf_multi = tfidf_vectorizer.transform(multi_train[\"clean_text\"])\n",
        "X_val_tfidf_multi   = tfidf_vectorizer.transform(multi_val[\"clean_text\"])\n",
        "X_test_tfidf_multi  = tfidf_vectorizer.transform(multi_test[\"clean_text\"])\n",
        "\n",
        "print(\"TF-IDF shapes (multi-class):\")\n",
        "print(\"X_train_tfidf_multi:\", X_train_tfidf_multi.shape)\n",
        "print(\"X_val_tfidf_multi:  \", X_val_tfidf_multi.shape)\n",
        "print(\"X_test_tfidf_multi: \", X_test_tfidf_multi.shape)\n"
      ],
      "metadata": {
        "id": "BykdoaMe5uk1"
      },
      "id": "BykdoaMe5uk1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word2Vec document vectors for multi-class***"
      ],
      "metadata": {
        "id": "2tdJzxda527C"
      },
      "id": "2tdJzxda527C"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Build document-level vectors using the existing Word2Vec model\n",
        "X_train_w2v_multi = np.vstack(\n",
        "    multi_train[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "X_val_w2v_multi = np.vstack(\n",
        "    multi_val[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "X_test_w2v_multi = np.vstack(\n",
        "    multi_test[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "\n",
        "print(\"Word2Vec document shapes (multi-class):\")\n",
        "print(\"X_train_w2v_multi:\", X_train_w2v_multi.shape)\n",
        "print(\"X_val_w2v_multi:  \", X_val_w2v_multi.shape)\n",
        "print(\"X_test_w2v_multi: \", X_test_w2v_multi.shape)\n"
      ],
      "metadata": {
        "id": "pg9D9Qy553Py"
      },
      "id": "pg9D9Qy553Py",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Evaluation helper (Accuracy, macro-F1, confusion matrix)***"
      ],
      "metadata": {
        "id": "0aNI705N5-dR"
      },
      "id": "0aNI705N5-dR"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "def evaluate_multi(model_name, representation_name, y_true, y_pred, label_encoder):\n",
        "    \"\"\"\n",
        "    Print accuracy, macro F1, and confusion matrix for a multi-class setting.\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== {model_name} + {representation_name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Macro F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n",
        "    print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(\"Label order:\", label_encoder.classes_)\n"
      ],
      "metadata": {
        "id": "5Gzkgjdw5_u-"
      },
      "id": "5Gzkgjdw5_u-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF + Multinomial Naive Bayes (3 classes)***"
      ],
      "metadata": {
        "id": "RIe_Y8Lz6DFw"
      },
      "id": "RIe_Y8Lz6DFw"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_tfidf_multi = MultinomialNB()\n",
        "nb_tfidf_multi.fit(X_train_tfidf_multi, y_train_multi)\n",
        "\n",
        "pred_val_nb_tfidf = nb_tfidf_multi.predict(X_val_tfidf_multi)\n",
        "\n",
        "evaluate_multi(\"Naive Bayes (Multinomial)\", \"TF-IDF\", y_val_multi, pred_val_nb_tfidf, le_multi)\n"
      ],
      "metadata": {
        "id": "IVV05-U-6EO6"
      },
      "id": "IVV05-U-6EO6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF + Logistic Regression (3 classes)***"
      ],
      "metadata": {
        "id": "xeA7FIvb6GOD"
      },
      "id": "xeA7FIvb6GOD"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_tfidf_multi = LogisticRegression(max_iter=2000)\n",
        "lr_tfidf_multi.fit(X_train_tfidf_multi, y_train_multi)\n",
        "\n",
        "pred_val_lr_tfidf = lr_tfidf_multi.predict(X_val_tfidf_multi)\n",
        "\n",
        "evaluate_multi(\"Logistic Regression\", \"TF-IDF\", y_val_multi, pred_val_lr_tfidf, le_multi)\n"
      ],
      "metadata": {
        "id": "Gls-UQsv6Gmt"
      },
      "id": "Gls-UQsv6Gmt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word2Vec + Gaussian Naive Bayes (3 classes)***"
      ],
      "metadata": {
        "id": "MMubVXrC6Q6P"
      },
      "id": "MMubVXrC6Q6P"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb_w2v_multi = GaussianNB()\n",
        "nb_w2v_multi.fit(X_train_w2v_multi, y_train_multi)\n",
        "\n",
        "pred_val_nb_w2v = nb_w2v_multi.predict(X_val_w2v_multi)\n",
        "\n",
        "evaluate_multi(\"Naive Bayes (Gaussian)\", \"Word2Vec\", y_val_multi, pred_val_nb_w2v, le_multi)\n"
      ],
      "metadata": {
        "id": "byh1RqoS6SYy"
      },
      "id": "byh1RqoS6SYy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word2Vec + Logistic Regression (3 classes)***"
      ],
      "metadata": {
        "id": "T2lZMuV_6Vnp"
      },
      "id": "T2lZMuV_6Vnp"
    },
    {
      "cell_type": "code",
      "source": [
        "lr_w2v_multi = LogisticRegression(max_iter=2000)\n",
        "lr_w2v_multi.fit(X_train_w2v_multi, y_train_multi)\n",
        "\n",
        "pred_val_lr_w2v = lr_w2v_multi.predict(X_val_w2v_multi)\n",
        "\n",
        "evaluate_multi(\"Logistic Regression\", \"Word2Vec\", y_val_multi, pred_val_lr_w2v, le_multi)\n"
      ],
      "metadata": {
        "id": "9E8l5hE66XVc"
      },
      "id": "9E8l5hE66XVc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Since our experiments clearly showed that TF-IDF consistently outperforms Word2Vec across all models and evaluation metrics, we decided to discontinue the use of Word2Vec and proceed exclusively with TF-IDF representations in the following stages***"
      ],
      "metadata": {
        "id": "wLHtEXAg0hlU"
      },
      "id": "wLHtEXAg0hlU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***הגדרת פונקצייה לניסויים בהיפר-פרמטרים***"
      ],
      "metadata": {
        "id": "leffEAvJ9v08"
      },
      "id": "leffEAvJ9v08"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def evaluate_scores(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute accuracy and macro F1 score.\n",
        "    \"\"\"\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    return acc, f1\n",
        "\n",
        "\n",
        "def tune_nb_tfidf(X_train, y_train, X_val, y_val, alphas, representation_name=\"TF-IDF\"):\n",
        "    \"\"\"\n",
        "    Hyperparameter tuning for Multinomial Naive Bayes on TF-IDF features.\n",
        "    Varies the smoothing parameter 'alpha' and prints validation performance.\n",
        "    Returns a list of results (alpha, accuracy, f1_macro).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    print(f\"\\n=== Naive Bayes (Multinomial) + {representation_name} — alpha sweep ===\")\n",
        "    for a in alphas:\n",
        "        model = MultinomialNB(alpha=a)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "        acc, f1 = evaluate_scores(y_val, y_pred)\n",
        "        results.append({\"alpha\": a, \"accuracy\": acc, \"f1_macro\": f1})\n",
        "        print(f\"alpha = {a:>4}  ->  Accuracy = {acc:.4f},  Macro F1 = {f1:.4f}\")\n",
        "    # Print best by F1\n",
        "    best = max(results, key=lambda r: r[\"f1_macro\"])\n",
        "    print(f\"\\nBest alpha by macro F1: {best['alpha']} (Accuracy={best['accuracy']:.4f}, F1={best['f1_macro']:.4f})\")\n",
        "    return results\n",
        "\n",
        "\n",
        "def tune_logistic(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    X_val,\n",
        "    y_val,\n",
        "    Cs,\n",
        "    max_iter=1000,\n",
        "    representation_name=\"TF-IDF\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Hyperparameter tuning for Logistic Regression on TF-IDF features.\n",
        "    Varies the regularization strength C and prints validation performance.\n",
        "    Returns a list of results (C, accuracy, f1_macro).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    print(f\"\\n=== Logistic Regression + {representation_name} — C sweep (max_iter={max_iter}) ===\")\n",
        "    for c in Cs:\n",
        "        clf = LogisticRegression(C=c, max_iter=max_iter)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_val)\n",
        "        acc, f1 = evaluate_scores(y_val, y_pred)\n",
        "        results.append({\"C\": c, \"accuracy\": acc, \"f1_macro\": f1})\n",
        "        print(f\"C = {c:>5}  ->  Accuracy = {acc:.4f},  Macro F1 = {f1:.4f}\")\n",
        "    # Print best by F1\n",
        "    best = max(results, key=lambda r: r[\"f1_macro\"])\n",
        "    print(f\"\\nBest C by macro F1: {best['C']} (Accuracy={best['accuracy']:.4f}, F1={best['f1_macro']:.4f})\")\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "NSL6hdnX910h"
      },
      "id": "NSL6hdnX910h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **תזכורת:**"
      ],
      "metadata": {
        "id": "krPxzvEhA9OL"
      },
      "id": "krPxzvEhA9OL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✔ Accuracy (דיוק)\n",
        "כמה אחוז מהניבואים של המודל היו נכונים מתוך כלל הדוגמאות.\n",
        "\n",
        "**איך להבין את זה?**  \n",
        "אם המודל ניחש נכון 70% מהפעמים → Accuracy = 0.70\n",
        "\n",
        "**מתי זה טוב?**  \n",
        "כאשר הדאטה מאוזן*\n",
        "(כל המחלקות מופיעות בערך באותה כמות).\n",
        "\n",
        "**החיסרון:**  \n",
        "אם מחלקה אחת מופיעה הרבה יותר – המדד עלול להיות מטעה.\n",
        "\n",
        "---\n",
        "\n",
        "### ✔ F1 Score (מדד F1)\n",
        "מדד שמחבר בין\n",
        " Precision ו־Recall\n",
        "  למדד אחד מאוזן.\n",
        "\n",
        "**איך להבין את זה?**  \n",
        " גבוה = המודל גם מוצא נכון דוגמאות של המחלקה וגם לא טועה הרבה.  \n",
        " נמוך = או שהמודל מפספס הרבה דוגמאות, או שהוא טועה הרבה.\n",
        "\n",
        "**מתי משתמשים בו?**  \n",
        "כאשר חשוב לזהות כל מחלקה בצורה טובה במיוחד,\n",
        "או כאשר יש אי־איזון בין המחלקות.\n",
        "\n",
        "---\n",
        "\n",
        "### ✔ Macro F1 (מדד F1 מאקרו)\n",
        "מחשב את ה\n",
        "F1\n",
        " לכל מחלקה בנפרד, ואז עושה ממוצע פשוט ביניהן.\n",
        "\n",
        "**איך להבין את זה?**  \n",
        "כל מחלקה מקבלת משקל שווה — גם אם יש ממנה מעט דוגמאות.\n",
        "\n",
        "**למה זה חשוב?**  \n",
        "כי בבעיות שבהן חלק מהמחלקות מופיעות מעט ,  \n",
        "Accuracy\n",
        " יכול להטעות,\n",
        "אבל\n",
        "Macro F1\n",
        "מוודא שהמודל מצליח גם על המחלקות הקטנות.\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "XKxwMcfsBAUN"
      },
      "id": "XKxwMcfsBAUN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ניסויים בהיפר פרמטרים***"
      ],
      "metadata": {
        "id": "dDp0khU2_rSd"
      },
      "id": "dDp0khU2_rSd"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Additional Hyperparameter Experiments (TF-IDF only)\n",
        "# ============================================\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 1) Naive Bayes + TF-IDF with more alpha values\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "nb_alphas_extended = [0.01, 0.1, 0.5, 1.0, 2.0]\n",
        "nb_tfidf_results_extended = tune_nb_tfidf(\n",
        "    X_train_tfidf_multi,\n",
        "    y_train_multi,\n",
        "    X_val_tfidf_multi,\n",
        "    y_val_multi,\n",
        "    alphas=nb_alphas_extended,\n",
        "    representation_name=\"TF-IDF (multi-class) — extended alpha\"\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 2) Logistic Regression + TF-IDF with extended C values\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "lr_C_extended = [0.01, 0.1, 1.0, 10.0, 50.0, 100.0]\n",
        "lr_tfidf_results_extended = tune_logistic(\n",
        "    X_train_tfidf_multi,\n",
        "    y_train_multi,\n",
        "    X_val_tfidf_multi,\n",
        "    y_val_multi,\n",
        "    Cs=lr_C_extended,\n",
        "    max_iter=3000,  # slightly higher, helps convergence\n",
        "    representation_name=\"TF-IDF (multi-class) — extended C\",\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 3) Logistic Regression + TF-IDF — small max_iter test\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "lr_tfidf_small_iter = tune_logistic(\n",
        "    X_train_tfidf_multi,\n",
        "    y_train_multi,\n",
        "    X_val_tfidf_multi,\n",
        "    y_val_multi,\n",
        "    Cs=[1.0],\n",
        "    max_iter=200,  # very small to check convergence behavior\n",
        "    representation_name=\"TF-IDF (multi-class) — small max_iter\",\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 4) Logistic Regression + TF-IDF — large max_iter test\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "lr_tfidf_large_iter = tune_logistic(\n",
        "    X_train_tfidf_multi,\n",
        "    y_train_multi,\n",
        "    X_val_tfidf_multi,\n",
        "    y_val_multi,\n",
        "    Cs=[1.0],\n",
        "    max_iter=5000,  # large enough to guarantee convergence\n",
        "    representation_name=\"TF-IDF (multi-class) — large max_iter\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "-FpUkxNY_uvG"
      },
      "id": "-FpUkxNY_uvG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***עד לפה זה החדש =========================================================================================================================================================================================================***"
      ],
      "metadata": {
        "id": "sIysXP7YjYPj"
      },
      "id": "sIysXP7YjYPj"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}