{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***עבור עמודות לבל וקוושטין בלבד - לכל השורות יצור קובץ בפורמט סי אס וי***\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "UjLzSyfik-zZ"
      },
      "id": "UjLzSyfik-zZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- שלב 1: קריאת קובץ ה-XLS ---\n",
        "import pandas as pd\n",
        "\n",
        "DATA_PATH = \"/content/train.xls\"\n",
        "# קרא את קובץ ה-XLS שנמצא באותה תקייה של הקולאב\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# --- שלב 2: חילוץ רק שתי עמודות ---\n",
        "filtered_df = df[[\"question\", \"level\"]]\n",
        "\n",
        "# --- שלב 2: מחיקת כפילויות ---\n",
        "filtered_df = filtered_df.drop_duplicates(subset=[\"question\"], keep=\"first\")\n",
        "\n",
        "# --- שלב 3: שמירה ל-CSV ---\n",
        "filtered_df.to_csv(\"train_filtered.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# הדפסה לווידוא\n",
        "filtered_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Q63ueADmjkXE",
        "outputId": "ac46d83f-6397-4e35-cc6a-8d8889e35c5d"
      },
      "id": "Q63ueADmjkXE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question   level\n",
              "0  Which magazine was started first Arthur's Maga...  medium\n",
              "1  The Oberoi family is part of a hotel company t...  medium\n",
              "2  Musician and satirist Allie Goertz wrote a son...    hard\n",
              "3    What nationality was James Henry Miller's wife?  medium\n",
              "4  Cadmium Chloride is slightly soluble in this c...  medium"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-effb5a9a-bacd-404c-95d6-fdd09d70dfc7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Which magazine was started first Arthur's Maga...</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Oberoi family is part of a hotel company t...</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
              "      <td>hard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What nationality was James Henry Miller's wife?</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cadmium Chloride is slightly soluble in this c...</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-effb5a9a-bacd-404c-95d6-fdd09d70dfc7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-effb5a9a-bacd-404c-95d6-fdd09d70dfc7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-effb5a9a-bacd-404c-95d6-fdd09d70dfc7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a2d07b97-201a-4f35-b8bd-c1fcbe8bdd79\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2d07b97-201a-4f35-b8bd-c1fcbe8bdd79')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a2d07b97-201a-4f35-b8bd-c1fcbe8bdd79 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "filtered_df",
              "summary": "{\n  \"name\": \"filtered_df\",\n  \"rows\": 90418,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90418,\n        \"samples\": [\n          \"What types of music strongly influenced the composer of Concerto Grosso?\",\n          \"James Earl Ray, was a convicted murderer who assassinated James Earl Ray, was a convicted murderer assassinated Martin Luther King Jr., an American Baptist minister and activist who became the most visible spokesperson and leader in the Civil Rights Movement, on which date, in Memphis, Tennessee? \",\n          \"Pippalada was an ancient Indian Vedic sage who was known to have written which ancient Sanskrit text, embedded inside Atharva Veda?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"medium\",\n          \"hard\",\n          \"easy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "אם מוסיפים את ה סי אס וי ידני אפשר להתחיל מפה"
      ],
      "metadata": {
        "id": "NKUr0jr7p-jw"
      },
      "id": "NKUr0jr7p-jw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***תרגיל 3 של הפרוייקט***"
      ],
      "metadata": {
        "id": "BWDmLmxFJX1B"
      },
      "id": "BWDmLmxFJX1B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***טעינת הקובץ - מחיקת כפיליות מ סי אס וי***"
      ],
      "metadata": {
        "id": "RjQoH_IxExFl"
      },
      "id": "RjQoH_IxExFl"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- שלב 1: טעינת הקובץ ---\n",
        "filtered_df = pd.read_csv(\"/content/train-filtered_question_level.csv\")\n",
        "\n",
        "# --- שלב 2: מחיקת כפילויות ---\n",
        "filtered_df = filtered_df.drop_duplicates(subset=[\"question\"], keep=\"first\")"
      ],
      "metadata": {
        "id": "fyfx1scUEqzU"
      },
      "id": "fyfx1scUEqzU",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***א-1***"
      ],
      "metadata": {
        "id": "f_aW02ESJLOo"
      },
      "id": "f_aW02ESJLOo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ייבוא ספריות ובדיקה ראשונית של התוויות***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5gm7encWEu_u"
      },
      "id": "5gm7encWEu_u"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Check that the expected columns exist and inspect the data\n",
        "print(filtered_df.columns)\n",
        "print(filtered_df.head())\n",
        "\n",
        "# Show global label distribution for 'level'\n",
        "print(\"\\nGlobal distribution of 'level':\")\n",
        "print(filtered_df[\"level\"].value_counts(normalize=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxymC_hSmq8K",
        "outputId": "8bca512f-f4ea-480f-9333-d77c5674bf7a"
      },
      "id": "sxymC_hSmq8K",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['question', 'level'], dtype='object')\n",
            "                                            question   level\n",
            "0  Which magazine was started first Arthur's Maga...  medium\n",
            "1  The Oberoi family is part of a hotel company t...  medium\n",
            "2  Musician and satirist Allie Goertz wrote a son...    hard\n",
            "3    What nationality was James Henry Miller's wife?  medium\n",
            "4  Cadmium Chloride is slightly soluble in this c...  medium\n",
            "\n",
            "Global distribution of 'level':\n",
            "level\n",
            "medium    0.628149\n",
            "easy      0.198688\n",
            "hard      0.173162\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***חלוקה מאוזנת ל־train / validation / test (עם stratify)***"
      ],
      "metadata": {
        "id": "2x9zwKKfpeX-"
      },
      "id": "2x9zwKKfpeX-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define split proportions\n",
        "TEST_SIZE = 0.15      # 15% of total data for test\n",
        "VAL_SIZE = 0.15       # 15% of total data for validation\n",
        "RANDOM_STATE = 42     # For reproducibility\n",
        "\n",
        "# Compute validation size relative to the remaining data after test split\n",
        "val_size_relative = VAL_SIZE / (1 - TEST_SIZE)  # e.g., 0.15 / 0.85\n",
        "\n",
        "print(\"Relative validation size (from train_val):\", val_size_relative)\n",
        "\n",
        "# Step 1: Split into train_val and test with stratification on 'level'\n",
        "train_val_df, test_df = train_test_split(\n",
        "    filtered_df,\n",
        "    test_size=TEST_SIZE,\n",
        "    stratify=filtered_df[\"level\"],\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Step 2: Split train_val into train and validation with stratification on 'level'\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df,\n",
        "    test_size=val_size_relative,\n",
        "    stratify=train_val_df[\"level\"],\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(\"Finished stratified split into train / validation / test.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m176qvlxpdZJ",
        "outputId": "9a10f7de-ce34-4708-a2c8-56bd49188c6f"
      },
      "id": "m176qvlxpdZJ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relative validation size (from train_val): 0.17647058823529413\n",
            "Finished stratified split into train / validation / test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***בדיקה שהחלוקה מאוזנת (stratified) ושיש לנו את היחסים הרצויים***"
      ],
      "metadata": {
        "id": "rpBACoIoplWC"
      },
      "id": "rpBACoIoplWC"
    },
    {
      "cell_type": "code",
      "source": [
        "def print_split_info(df, name):\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(\"Number of rows:\", len(df))\n",
        "    print(\"Label distribution for 'level':\")\n",
        "    print(df[\"level\"].value_counts(normalize=True))\n",
        "\n",
        "print(\"Total rows in original filtered_df:\", len(filtered_df))\n",
        "\n",
        "print_split_info(train_df, \"Train set\")\n",
        "print_split_info(val_df, \"Validation set\")\n",
        "print_split_info(test_df, \"Test set\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pev31-BLplxP",
        "outputId": "bfd4c000-5a99-4379-e5ae-2472564640d8"
      },
      "id": "pev31-BLplxP",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows in original filtered_df: 90418\n",
            "\n",
            "Train set:\n",
            "Number of rows: 63292\n",
            "Label distribution for 'level':\n",
            "level\n",
            "medium    0.628152\n",
            "easy      0.198682\n",
            "hard      0.173166\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Validation set:\n",
            "Number of rows: 13563\n",
            "Label distribution for 'level':\n",
            "level\n",
            "medium    0.628180\n",
            "easy      0.198702\n",
            "hard      0.173118\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Test set:\n",
            "Number of rows: 13563\n",
            "Label distribution for 'level':\n",
            "level\n",
            "medium    0.628106\n",
            "easy      0.198702\n",
            "hard      0.173192\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **א-2**"
      ],
      "metadata": {
        "id": "KtfJcpMAJofI"
      },
      "id": "KtfJcpMAJofI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Text preprocessing (tokenization + lemmatization)***"
      ],
      "metadata": {
        "id": "zeHPEQzQJsf6"
      },
      "id": "zeHPEQzQJsf6"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize, pos_tag\n",
        "\n",
        "# Download required NLTK resources (only once)\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "eng_stops = set(stopwords.words(\"english\"))\n",
        "BE_FORMS = {\"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\"}\n",
        "\n",
        "def get_wordnet_pos(tag: str):\n",
        "    \"\"\"\n",
        "    Map POS tag from nltk.pos_tag to a WordNet POS tag.\n",
        "    This helps the lemmatizer pick the correct base form.\n",
        "    \"\"\"\n",
        "    if tag.startswith(\"J\"):\n",
        "        return wordnet.ADJ\n",
        "    if tag.startswith(\"V\"):\n",
        "        return wordnet.VERB\n",
        "    if tag.startswith(\"N\"):\n",
        "        return wordnet.NOUN\n",
        "    if tag.startswith(\"R\"):\n",
        "        return wordnet.ADV\n",
        "    return wordnet.NOUN\n",
        "\n",
        "# Regex patterns for cleaning\n",
        "url_email_handle_re = re.compile(r\"(https?://\\S+|www\\.\\S+|\\S+@\\S+|[@#]\\w+)\", re.IGNORECASE)\n",
        "digits_re = re.compile(r\"\\d+\")            # digits -> _number\n",
        "non_letter_re = re.compile(r\"[^a-z_ ]+\")  # after lowercase, keep only a-z, space, underscore\n",
        "\n",
        "def process_text_value(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Full preprocessing for a single text value:\n",
        "    - Remove URLs, emails, and @handles/#hashtags\n",
        "    - Tokenize\n",
        "    - POS tagging\n",
        "    - Lemmatization with POS\n",
        "    - Normalize 'be' verb forms\n",
        "    - Replace digits with '_number'\n",
        "    - Remove non-letter characters (keep a-z, space, underscore)\n",
        "    - Remove stopwords\n",
        "    - Lowercase\n",
        "    Returns a cleaned string with space-separated tokens.\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    t = text\n",
        "\n",
        "    # Remove URLs, emails, handles, hashtags\n",
        "    t = url_email_handle_re.sub(\" \", t)\n",
        "\n",
        "    # Tokenize and POS-tag on original text\n",
        "    tokens = word_tokenize(t)\n",
        "    tagged = pos_tag(tokens)\n",
        "\n",
        "    lemmas = []\n",
        "    for tok, pos in tagged:\n",
        "        # Normalize 'be' forms early\n",
        "        if tok.lower() in BE_FORMS:\n",
        "            lemmas.append(\"be\")\n",
        "            continue\n",
        "\n",
        "        # Map tag to WordNet POS and lemmatize\n",
        "        wn_pos = get_wordnet_pos(pos)\n",
        "        lemma = lemmatizer.lemmatize(tok, wn_pos)\n",
        "        lemmas.append(lemma)\n",
        "\n",
        "    # Lowercase\n",
        "    lemmas = [w.lower() for w in lemmas]\n",
        "\n",
        "    # Replace digits inside tokens with '_number'\n",
        "    lemmas = [digits_re.sub(\"_number\", w) for w in lemmas]\n",
        "\n",
        "    # Keep only a-z / underscore / spaces, and clean token by token\n",
        "    clean_lemmas = []\n",
        "    for w in lemmas:\n",
        "        w2 = non_letter_re.sub(\" \", w).strip()\n",
        "        if not w2:\n",
        "            continue\n",
        "        # If cleaning produced multiple parts, split them\n",
        "        for part in w2.split():\n",
        "            clean_lemmas.append(part)\n",
        "\n",
        "    # # Remove stopwords\n",
        "    # clean_lemmas = [w for w in clean_lemmas if w not in eng_stops]\n",
        "\n",
        "    # Join back into a single string\n",
        "    return \" \".join(clean_lemmas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toAKXIEoMcY3",
        "outputId": "b32f72c3-e1d2-4b14-dd2d-de3c46b9dccc"
      },
      "id": "toAKXIEoMcY3",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Apply preprocessing to train / val / test***"
      ],
      "metadata": {
        "id": "qwOP_ovgRKwO"
      },
      "id": "qwOP_ovgRKwO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply processing to 'question' column in each split\n",
        "train_df[\"clean_text\"] = train_df[\"question\"].apply(process_text_value)\n",
        "val_df[\"clean_text\"]   = val_df[\"question\"].apply(process_text_value)\n",
        "test_df[\"clean_text\"]  = test_df[\"question\"].apply(process_text_value)\n",
        "\n",
        "# Also create a token list from the cleaned string (for Word2Vec etc.)\n",
        "train_df[\"tokens\"] = train_df[\"clean_text\"].apply(lambda s: s.split())\n",
        "val_df[\"tokens\"]   = val_df[\"clean_text\"].apply(lambda s: s.split())\n",
        "test_df[\"tokens\"]  = test_df[\"clean_text\"].apply(lambda s: s.split())\n",
        "\n",
        "train_df[[\"question\", \"clean_text\"]].head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VPjsviBsQxIg",
        "outputId": "da4387ba-4fc7-4093-ac79-df9412b1e3f3"
      },
      "id": "VPjsviBsQxIg",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                question  \\\n",
              "72693  How many studio albums has the band that playe...   \n",
              "24973  When was the team that won the 1981-82 Turkish...   \n",
              "19388  What genre of music do Sonic Reign and Emperor...   \n",
              "67473                       What is Rollkommando Hamann?   \n",
              "62224  Who starred with Jay Mohr in a 1997 American r...   \n",
              "\n",
              "                                              clean_text  \n",
              "72693   many studio album band play warrior call release  \n",
              "24973  team win _number _number turkish first footbal...  \n",
              "19388               genre music sonic reign emperor fall  \n",
              "67473                                rollkommando hamann  \n",
              "62224     star jay mohr _number american romantic comedy  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acda197c-91fb-4ec8-a85e-bfc5f12ad919\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>72693</th>\n",
              "      <td>How many studio albums has the band that playe...</td>\n",
              "      <td>many studio album band play warrior call release</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24973</th>\n",
              "      <td>When was the team that won the 1981-82 Turkish...</td>\n",
              "      <td>team win _number _number turkish first footbal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19388</th>\n",
              "      <td>What genre of music do Sonic Reign and Emperor...</td>\n",
              "      <td>genre music sonic reign emperor fall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67473</th>\n",
              "      <td>What is Rollkommando Hamann?</td>\n",
              "      <td>rollkommando hamann</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62224</th>\n",
              "      <td>Who starred with Jay Mohr in a 1997 American r...</td>\n",
              "      <td>star jay mohr _number american romantic comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acda197c-91fb-4ec8-a85e-bfc5f12ad919')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-acda197c-91fb-4ec8-a85e-bfc5f12ad919 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-acda197c-91fb-4ec8-a85e-bfc5f12ad919');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-25880070-5507-4345-9a1c-2ce591179bc1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25880070-5507-4345-9a1c-2ce591179bc1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-25880070-5507-4345-9a1c-2ce591179bc1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_df[[\\\"question\\\", \\\"clean_text\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"When was the team that won the 1981-82 Turkish First Football League championship founded?\",\n          \"Who starred with Jay Mohr in a 1997 American romantic comedy?\",\n          \"What genre of music do Sonic Reign and Emperor fall under?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"team win _number _number turkish first football league championship found\",\n          \"star jay mohr _number american romantic comedy\",\n          \"genre music sonic reign emperor fall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF representation (document → vector)***"
      ],
      "metadata": {
        "id": "ovO3e28_RrXX"
      },
      "id": "ovO3e28_RrXX"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Define a TF-IDF vectorizer\n",
        "# You can adjust max_features depending on dataset size\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=10000,   # limit vocabulary size (optional)\n",
        "    ngram_range=(1, 1),   # unigrams only\n",
        ")\n",
        "\n",
        "# Fit on train set and transform all splits\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"clean_text\"])\n",
        "X_val_tfidf   = tfidf_vectorizer.transform(val_df[\"clean_text\"])\n",
        "X_test_tfidf  = tfidf_vectorizer.transform(test_df[\"clean_text\"])\n",
        "\n",
        "print(\"TF-IDF shapes:\")\n",
        "print(\"X_train_tfidf:\", X_train_tfidf.shape)\n",
        "print(\"X_val_tfidf:  \", X_val_tfidf.shape)\n",
        "print(\"X_test_tfidf: \", X_test_tfidf.shape)\n",
        "print(\"(Num of documents, max_features)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqDPZN-mRvtC",
        "outputId": "18a1606e-2c61-4190-cd04-cc5e52ec6e9c"
      },
      "id": "tqDPZN-mRvtC",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF shapes:\n",
            "X_train_tfidf: (63292, 10000)\n",
            "X_val_tfidf:   (13563, 10000)\n",
            "X_test_tfidf:  (13563, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Train Word2Vec on tokens (word embeddings)***"
      ],
      "metadata": {
        "id": "AsSG0mtZJrEL"
      },
      "id": "AsSG0mtZJrEL"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Prepare sentences for Word2Vec (list of token lists)\n",
        "train_sentences = train_df[\"tokens\"].tolist()\n",
        "\n",
        "# Train a Word2Vec model on the training set only\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=train_sentences,\n",
        "    vector_size=100,   # size of word vectors\n",
        "    window=5,          # context window\n",
        "    min_count=2,       # ignore words with total frequency < 2\n",
        "    workers=4,         # number of CPU threads (Colab usually supports this)\n",
        "    sg=1,              # 1 = skip-gram, 0 = CBOW\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(\"Word2Vec model trained.\")\n",
        "print(\"Vocabulary size:\", len(w2v_model.wv.key_to_index))\n",
        "print(\"Vector size:\", w2v_model.vector_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZm-oaYnR7-j",
        "outputId": "687340c8-1c19-48b2-a5e6-6953ec8f75f0"
      },
      "id": "fZm-oaYnR7-j",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n",
            "Word2Vec model trained.\n",
            "Vocabulary size: 26984\n",
            "Vector size: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Build document vectors from Word2Vec (TF-IDF weighted average)***"
      ],
      "metadata": {
        "id": "5ke7Pi-KUlGD"
      },
      "id": "5ke7Pi-KUlGD"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Build a dictionary: word -> IDF score, based on the TF-IDF vocabulary\n",
        "idf_scores = dict(zip(tfidf_vectorizer.get_feature_names_out(),\n",
        "                      tfidf_vectorizer.idf_))\n",
        "\n",
        "def document_vector(tokens, use_tfidf_weight=True):\n",
        "    \"\"\"\n",
        "    Compute a single document vector from word vectors.\n",
        "    By default uses TF-IDF weights as recommended.\n",
        "    - tokens: list of preprocessed, lemmatized tokens\n",
        "    - use_tfidf_weight: if True, weight each word vector by its IDF\n",
        "    \"\"\"\n",
        "    vectors = []\n",
        "    weights = []\n",
        "\n",
        "    for tok in tokens:\n",
        "        if tok in w2v_model.wv:\n",
        "            vec = w2v_model.wv[tok]\n",
        "            if use_tfidf_weight:\n",
        "                weight = idf_scores.get(tok, 1.0)\n",
        "            else:\n",
        "                weight = 1.0\n",
        "            vectors.append(vec * weight)\n",
        "            weights.append(weight)\n",
        "\n",
        "    if not vectors:\n",
        "        # If no token has a vector, return a zero vector\n",
        "        return np.zeros(w2v_model.vector_size, dtype=np.float32)\n",
        "\n",
        "    vectors = np.vstack(vectors)\n",
        "    weights = np.array(weights, dtype=np.float32)\n",
        "\n",
        "    # Weighted average: sum(w_i * v_i) / sum(w_i)\n",
        "    return vectors.sum(axis=0) / weights.sum()\n",
        "\n",
        "# Build document-level vectors for each split\n",
        "X_train_w2v = np.vstack(train_df[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True)))\n",
        "X_val_w2v   = np.vstack(val_df[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True)))\n",
        "X_test_w2v  = np.vstack(test_df[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True)))\n",
        "\n",
        "print(\"Word2Vec document matrices shapes:\")\n",
        "print(\"X_train_w2v:\", X_train_w2v.shape)\n",
        "print(\"X_val_w2v:  \", X_val_w2v.shape)\n",
        "print(\"X_test_w2v: \", X_test_w2v.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwRZS0yDUudb",
        "outputId": "96d5dde3-bb20-4acc-bb04-a57757ade842"
      },
      "id": "ZwRZS0yDUudb",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec document matrices shapes:\n",
            "X_train_w2v: (63292, 100)\n",
            "X_val_w2v:   (13563, 100)\n",
            "X_test_w2v:  (13563, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***ב-1-סיווג בינארי***"
      ],
      "metadata": {
        "id": "2HJK_nb4xcES"
      },
      "id": "2HJK_nb4xcES"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Filter to binary classes (easy, hard)***"
      ],
      "metadata": {
        "id": "AdkAzZ-Q11NJ"
      },
      "id": "AdkAzZ-Q11NJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only 'easy' and 'hard' classes\n",
        "binary_train = train_df[train_df[\"level\"].isin([\"easy\", \"hard\"])].copy()\n",
        "binary_val   = val_df[val_df[\"level\"].isin([\"easy\", \"hard\"])].copy()\n",
        "binary_test  = test_df[test_df[\"level\"].isin([\"easy\", \"hard\"])].copy()\n",
        "\n",
        "print(\"Train size:\", len(binary_train))\n",
        "print(\"Validation size:\", len(binary_val))\n",
        "print(\"Test size:\", len(binary_test))\n",
        "\n",
        "print(\"\\nTrain label distribution:\")\n",
        "print(binary_train[\"level\"].value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "NcjvK2Ndxcf8",
        "outputId": "3d0f7306-c080-49e0-9419-e2629a2a9750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NcjvK2Ndxcf8",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 23535\n",
            "Validation size: 5043\n",
            "Test size: 5044\n",
            "\n",
            "Train label distribution:\n",
            "level\n",
            "easy    0.534311\n",
            "hard    0.465689\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Encode labels (easy=0, hard=1)***"
      ],
      "metadata": {
        "id": "ZaCcDxS601Pd"
      },
      "id": "ZaCcDxS601Pd"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "y_train = le.fit_transform(binary_train[\"level\"])\n",
        "y_val   = le.transform(binary_val[\"level\"])\n",
        "y_test  = le.transform(binary_test[\"level\"])\n",
        "\n",
        "print(\"Label classes:\", le.classes_)  # ['easy' 'hard']\n"
      ],
      "metadata": {
        "id": "egO2tI2e07eI",
        "outputId": "bc4c55a4-91b3-4f28-b5f6-9a05f5e7acf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "egO2tI2e07eI",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label classes: ['easy' 'hard']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Build TF-IDF for the binary subsets***"
      ],
      "metadata": {
        "id": "kkibpNFb08Gx"
      },
      "id": "kkibpNFb08Gx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse the same TF-IDF vectorizer that was already fitted on full train_df\n",
        "X_train_tfidf_bin = tfidf_vectorizer.transform(binary_train[\"clean_text\"])\n",
        "X_val_tfidf_bin   = tfidf_vectorizer.transform(binary_val[\"clean_text\"])\n",
        "X_test_tfidf_bin  = tfidf_vectorizer.transform(binary_test[\"clean_text\"])\n",
        "\n",
        "print(\"Binary TF-IDF shapes:\")\n",
        "print(\"X_train_tfidf_bin:\", X_train_tfidf_bin.shape)\n",
        "print(\"X_val_tfidf_bin:  \", X_val_tfidf_bin.shape)\n",
        "print(\"X_test_tfidf_bin: \", X_test_tfidf_bin.shape)\n"
      ],
      "metadata": {
        "id": "O2qL3tCy08wD",
        "outputId": "34051bf4-891c-40e4-a5e6-5849d6adb0c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "O2qL3tCy08wD",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary TF-IDF shapes:\n",
            "X_train_tfidf_bin: (23535, 10000)\n",
            "X_val_tfidf_bin:   (5043, 10000)\n",
            "X_test_tfidf_bin:  (5044, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Build Word2Vec document vectors for the binary subsets***"
      ],
      "metadata": {
        "id": "6JT2DoNx23au"
      },
      "id": "6JT2DoNx23au"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming you already have w2v_model and document_vector() defined\n",
        "\n",
        "X_train_w2v_bin = np.vstack(\n",
        "    binary_train[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "X_val_w2v_bin = np.vstack(\n",
        "    binary_val[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "X_test_w2v_bin = np.vstack(\n",
        "    binary_test[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "\n",
        "print(\"Binary Word2Vec shapes:\")\n",
        "print(\"X_train_w2v_bin:\", X_train_w2v_bin.shape)\n",
        "print(\"X_val_w2v_bin:  \", X_val_w2v_bin.shape)\n",
        "print(\"X_test_w2v_bin: \", X_test_w2v_bin.shape)\n"
      ],
      "metadata": {
        "id": "YdtdkzqG21nt",
        "outputId": "e9b97d1a-f529-47fc-e2fb-64d50821904e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YdtdkzqG21nt",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Word2Vec shapes:\n",
            "X_train_w2v_bin: (23535, 100)\n",
            "X_val_w2v_bin:   (5043, 100)\n",
            "X_test_w2v_bin:  (5044, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Utility: evaluate model***"
      ],
      "metadata": {
        "id": "wgrwWdZi1LvQ"
      },
      "id": "wgrwWdZi1LvQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "def evaluate_model(model_name, representation_name, y_true, y_pred):\n",
        "    print(f\"\\n=== {model_name} + {representation_name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "9DI7lMjR1Q07"
      },
      "id": "9DI7lMjR1Q07",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF + Naive Bayes***"
      ],
      "metadata": {
        "id": "ycZgqE4Q1ZIl"
      },
      "id": "ycZgqE4Q1ZIl"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_tfidf = MultinomialNB()\n",
        "nb_tfidf.fit(X_train_tfidf_bin, y_train)\n",
        "\n",
        "pred_val = nb_tfidf.predict(X_val_tfidf_bin)\n",
        "\n",
        "evaluate_model(\"Naive Bayes\", \"TF-IDF\", y_val, pred_val)\n"
      ],
      "metadata": {
        "id": "WN4QUQm11dqL",
        "outputId": "47323884-47e8-45f7-ab77-14291414f4b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WN4QUQm11dqL",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Naive Bayes + TF-IDF ===\n",
            "Accuracy: 0.6014277215942891\n",
            "F1 Score: 0.4964929859719439\n",
            "Confusion Matrix:\n",
            " [[2042  653]\n",
            " [1357  991]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF + Logistic Regression***"
      ],
      "metadata": {
        "id": "W5XLMNuQ1eFx"
      },
      "id": "W5XLMNuQ1eFx"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_tfidf = LogisticRegression(max_iter=2000)\n",
        "lr_tfidf.fit(X_train_tfidf_bin, y_train)\n",
        "\n",
        "pred_val = lr_tfidf.predict(X_val_tfidf_bin)\n",
        "\n",
        "evaluate_model(\"Logistic Regression\", \"TF-IDF\", y_val, pred_val)\n"
      ],
      "metadata": {
        "id": "6lSuSL5Q1erE",
        "outputId": "fd38eff7-1ee7-42f1-a80e-338461b109a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6lSuSL5Q1erE",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression + TF-IDF ===\n",
            "Accuracy: 0.6652786040055523\n",
            "F1 Score: 0.631601920558708\n",
            "Confusion Matrix:\n",
            " [[1908  787]\n",
            " [ 901 1447]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word2Vec + Naive Bayes***"
      ],
      "metadata": {
        "id": "BDQ-NH5I1fi_"
      },
      "id": "BDQ-NH5I1fi_"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb_w2v = GaussianNB()\n",
        "nb_w2v.fit(X_train_w2v_bin, y_train)\n",
        "\n",
        "pred_val = nb_w2v.predict(X_val_w2v_bin)\n",
        "\n",
        "evaluate_model(\"Naive Bayes (Gaussian)\", \"Word2Vec\", y_val, pred_val)\n"
      ],
      "metadata": {
        "id": "UHl9DRK-1p3W",
        "outputId": "e2831604-42b9-41a2-f162-16bb9aece299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UHl9DRK-1p3W",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Naive Bayes (Gaussian) + Word2Vec ===\n",
            "Accuracy: 0.5683125123934166\n",
            "F1 Score: 0.4553415061295972\n",
            "Confusion Matrix:\n",
            " [[1956  739]\n",
            " [1438  910]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word2Vec + Logistic Regression***"
      ],
      "metadata": {
        "id": "iMBIEtHy1roq"
      },
      "id": "iMBIEtHy1roq"
    },
    {
      "cell_type": "code",
      "source": [
        "lr_w2v = LogisticRegression(max_iter=2000)\n",
        "lr_w2v.fit(X_train_w2v_bin, y_train)\n",
        "\n",
        "pred_val = lr_w2v.predict(X_val_w2v_bin)\n",
        "\n",
        "evaluate_model(\"Logistic Regression\", \"Word2Vec\", y_val, pred_val)\n"
      ],
      "metadata": {
        "id": "FT8d4Wnv1ul2",
        "outputId": "fc171f5a-97e3-41aa-f73a-39dfd5f08a0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FT8d4Wnv1ul2",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression + Word2Vec ===\n",
            "Accuracy: 0.6178861788617886\n",
            "F1 Score: 0.5386641129997606\n",
            "Confusion Matrix:\n",
            " [[1991  704]\n",
            " [1223 1125]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***ב-1- סיווג רב מחלקתי כלומר 3***"
      ],
      "metadata": {
        "id": "faKA2iZN5NsH"
      },
      "id": "faKA2iZN5NsH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Build multi-class subsets (easy, medium, hard)***"
      ],
      "metadata": {
        "id": "dpfRTFW25cZ5"
      },
      "id": "dpfRTFW25cZ5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only the three target classes\n",
        "target_levels = [\"easy\", \"medium\", \"hard\"]\n",
        "\n",
        "multi_train = train_df[train_df[\"level\"].isin(target_levels)].copy()\n",
        "multi_val   = val_df[val_df[\"level\"].isin(target_levels)].copy()\n",
        "multi_test  = test_df[test_df[\"level\"].isin(target_levels)].copy()\n",
        "\n",
        "print(\"Train size:\", len(multi_train))\n",
        "print(\"Validation size:\", len(multi_val))\n",
        "print(\"Test size:\", len(multi_test))\n",
        "\n",
        "print(\"\\nTrain label distribution:\")\n",
        "print(multi_train[\"level\"].value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nUnique levels in all splits:\")\n",
        "print(\"Train:\", multi_train[\"level\"].unique())\n",
        "print(\"Val:  \", multi_val[\"level\"].unique())\n",
        "print(\"Test: \", multi_test[\"level\"].unique())\n"
      ],
      "metadata": {
        "id": "GRO-qxBV5c0J",
        "outputId": "59accaf1-dbcf-4a59-8538-fa6ca09c96ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GRO-qxBV5c0J",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 63292\n",
            "Validation size: 13563\n",
            "Test size: 13563\n",
            "\n",
            "Train label distribution:\n",
            "level\n",
            "medium    0.628152\n",
            "easy      0.198682\n",
            "hard      0.173166\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Unique levels in all splits:\n",
            "Train: ['medium' 'hard' 'easy']\n",
            "Val:   ['hard' 'medium' 'easy']\n",
            "Test:  ['medium' 'easy' 'hard']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Encode labels (3 classes)***"
      ],
      "metadata": {
        "id": "5hSpOfJ95ocX"
      },
      "id": "5hSpOfJ95ocX"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le_multi = LabelEncoder()\n",
        "\n",
        "y_train_multi = le_multi.fit_transform(multi_train[\"level\"])\n",
        "y_val_multi   = le_multi.transform(multi_val[\"level\"])\n",
        "y_test_multi  = le_multi.transform(multi_test[\"level\"])\n",
        "\n",
        "print(\"Label classes (order):\", le_multi.classes_)  # expects ['easy' 'hard' 'medium'] or similar\n"
      ],
      "metadata": {
        "id": "u9v-DDlP5owa",
        "outputId": "1fa17b08-59f9-4a1e-b094-6e97a4d65ef1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "u9v-DDlP5owa",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label classes (order): ['easy' 'hard' 'medium']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF representation for multi-class***"
      ],
      "metadata": {
        "id": "ukMMIGQQ5uQv"
      },
      "id": "ukMMIGQQ5uQv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform clean_text into TF-IDF vectors using the existing fitted vectorizer\n",
        "X_train_tfidf_multi = tfidf_vectorizer.transform(multi_train[\"clean_text\"])\n",
        "X_val_tfidf_multi   = tfidf_vectorizer.transform(multi_val[\"clean_text\"])\n",
        "X_test_tfidf_multi  = tfidf_vectorizer.transform(multi_test[\"clean_text\"])\n",
        "\n",
        "print(\"TF-IDF shapes (multi-class):\")\n",
        "print(\"X_train_tfidf_multi:\", X_train_tfidf_multi.shape)\n",
        "print(\"X_val_tfidf_multi:  \", X_val_tfidf_multi.shape)\n",
        "print(\"X_test_tfidf_multi: \", X_test_tfidf_multi.shape)\n"
      ],
      "metadata": {
        "id": "BykdoaMe5uk1",
        "outputId": "e2acd00a-aa28-4bed-ad71-0210a5809e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BykdoaMe5uk1",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF shapes (multi-class):\n",
            "X_train_tfidf_multi: (63292, 10000)\n",
            "X_val_tfidf_multi:   (13563, 10000)\n",
            "X_test_tfidf_multi:  (13563, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word2Vec document vectors for multi-class***"
      ],
      "metadata": {
        "id": "2tdJzxda527C"
      },
      "id": "2tdJzxda527C"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Build document-level vectors using the existing Word2Vec model\n",
        "X_train_w2v_multi = np.vstack(\n",
        "    multi_train[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "X_val_w2v_multi = np.vstack(\n",
        "    multi_val[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "X_test_w2v_multi = np.vstack(\n",
        "    multi_test[\"tokens\"].apply(lambda toks: document_vector(toks, use_tfidf_weight=True))\n",
        ")\n",
        "\n",
        "print(\"Word2Vec document shapes (multi-class):\")\n",
        "print(\"X_train_w2v_multi:\", X_train_w2v_multi.shape)\n",
        "print(\"X_val_w2v_multi:  \", X_val_w2v_multi.shape)\n",
        "print(\"X_test_w2v_multi: \", X_test_w2v_multi.shape)\n"
      ],
      "metadata": {
        "id": "pg9D9Qy553Py",
        "outputId": "1409daaa-561b-48f0-9447-0c6c7d1775d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pg9D9Qy553Py",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec document shapes (multi-class):\n",
            "X_train_w2v_multi: (63292, 100)\n",
            "X_val_w2v_multi:   (13563, 100)\n",
            "X_test_w2v_multi:  (13563, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Evaluation helper (Accuracy, macro-F1, confusion matrix)***"
      ],
      "metadata": {
        "id": "0aNI705N5-dR"
      },
      "id": "0aNI705N5-dR"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "def evaluate_multi(model_name, representation_name, y_true, y_pred, label_encoder):\n",
        "    \"\"\"\n",
        "    Print accuracy, macro F1, and confusion matrix for a multi-class setting.\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== {model_name} + {representation_name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Macro F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n",
        "    print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(\"Label order:\", label_encoder.classes_)\n"
      ],
      "metadata": {
        "id": "5Gzkgjdw5_u-"
      },
      "id": "5Gzkgjdw5_u-",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF + Multinomial Naive Bayes (3 classes)***"
      ],
      "metadata": {
        "id": "RIe_Y8Lz6DFw"
      },
      "id": "RIe_Y8Lz6DFw"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_tfidf_multi = MultinomialNB()\n",
        "nb_tfidf_multi.fit(X_train_tfidf_multi, y_train_multi)\n",
        "\n",
        "pred_val_nb_tfidf = nb_tfidf_multi.predict(X_val_tfidf_multi)\n",
        "\n",
        "evaluate_multi(\"Naive Bayes (Multinomial)\", \"TF-IDF\", y_val_multi, pred_val_nb_tfidf, le_multi)\n"
      ],
      "metadata": {
        "id": "IVV05-U-6EO6",
        "outputId": "e9462af4-26ae-49b4-f917-58b76923e735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IVV05-U-6EO6",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Naive Bayes (Multinomial) + TF-IDF ===\n",
            "Accuracy: 0.6323822163238222\n",
            "Macro F1: 0.28222654756253046\n",
            "\n",
            "Confusion Matrix (rows=true, cols=pred):\n",
            "[[  99   11 2585]\n",
            " [  17    4 2327]\n",
            " [  32   14 8474]]\n",
            "Label order: ['easy' 'hard' 'medium']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TF-IDF + Logistic Regression (3 classes)***"
      ],
      "metadata": {
        "id": "xeA7FIvb6GOD"
      },
      "id": "xeA7FIvb6GOD"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_tfidf_multi = LogisticRegression(max_iter=2000)\n",
        "lr_tfidf_multi.fit(X_train_tfidf_multi, y_train_multi)\n",
        "\n",
        "pred_val_lr_tfidf = lr_tfidf_multi.predict(X_val_tfidf_multi)\n",
        "\n",
        "evaluate_multi(\"Logistic Regression\", \"TF-IDF\", y_val_multi, pred_val_lr_tfidf, le_multi)\n"
      ],
      "metadata": {
        "id": "Gls-UQsv6Gmt",
        "outputId": "8bd84351-8c03-4c50-c8f7-15d26674ca62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Gls-UQsv6Gmt",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression + TF-IDF ===\n",
            "Accuracy: 0.6435154464351545\n",
            "Macro F1: 0.3894805596490973\n",
            "\n",
            "Confusion Matrix (rows=true, cols=pred):\n",
            "[[ 732   27 1936]\n",
            " [ 126   38 2184]\n",
            " [ 451  111 7958]]\n",
            "Label order: ['easy' 'hard' 'medium']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word2Vec + Gaussian Naive Bayes (3 classes)***"
      ],
      "metadata": {
        "id": "MMubVXrC6Q6P"
      },
      "id": "MMubVXrC6Q6P"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb_w2v_multi = GaussianNB()\n",
        "nb_w2v_multi.fit(X_train_w2v_multi, y_train_multi)\n",
        "\n",
        "pred_val_nb_w2v = nb_w2v_multi.predict(X_val_w2v_multi)\n",
        "\n",
        "evaluate_multi(\"Naive Bayes (Gaussian)\", \"Word2Vec\", y_val_multi, pred_val_nb_w2v, le_multi)\n"
      ],
      "metadata": {
        "id": "byh1RqoS6SYy",
        "outputId": "63c224f4-2a9f-440d-e79b-14c18bba8aa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "byh1RqoS6SYy",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Naive Bayes (Gaussian) + Word2Vec ===\n",
            "Accuracy: 0.43567057435670575\n",
            "Macro F1: 0.35943072535855597\n",
            "\n",
            "Confusion Matrix (rows=true, cols=pred):\n",
            "[[1388  357  950]\n",
            " [ 972  370 1006]\n",
            " [3119 1250 4151]]\n",
            "Label order: ['easy' 'hard' 'medium']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word2Vec + Logistic Regression (3 classes)***"
      ],
      "metadata": {
        "id": "T2lZMuV_6Vnp"
      },
      "id": "T2lZMuV_6Vnp"
    },
    {
      "cell_type": "code",
      "source": [
        "lr_w2v_multi = LogisticRegression(max_iter=2000)\n",
        "lr_w2v_multi.fit(X_train_w2v_multi, y_train_multi)\n",
        "\n",
        "pred_val_lr_w2v = lr_w2v_multi.predict(X_val_w2v_multi)\n",
        "\n",
        "evaluate_multi(\"Logistic Regression\", \"Word2Vec\", y_val_multi, pred_val_lr_w2v, le_multi)\n"
      ],
      "metadata": {
        "id": "9E8l5hE66XVc",
        "outputId": "cb964966-2bbb-49e3-e42e-677450b81013",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9E8l5hE66XVc",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression + Word2Vec ===\n",
            "Accuracy: 0.6273685762736858\n",
            "Macro F1: 0.2779021393580056\n",
            "\n",
            "Confusion Matrix (rows=true, cols=pred):\n",
            "[[  93    0 2602]\n",
            " [  24    0 2324]\n",
            " [ 104    0 8416]]\n",
            "Label order: ['easy' 'hard' 'medium']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***הגדרת פונקצייה לניסויים בהיפר-פרמטרים***"
      ],
      "metadata": {
        "id": "leffEAvJ9v08"
      },
      "id": "leffEAvJ9v08"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def evaluate_scores(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute accuracy and macro F1 score.\n",
        "    \"\"\"\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    return acc, f1\n",
        "\n",
        "\n",
        "def tune_nb_tfidf(X_train, y_train, X_val, y_val, alphas, representation_name=\"TF-IDF\"):\n",
        "    \"\"\"\n",
        "    Hyperparameter tuning for Multinomial Naive Bayes on TF-IDF features.\n",
        "    Varies the smoothing parameter 'alpha' and prints validation performance.\n",
        "    Returns a list of results (alpha, accuracy, f1).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    print(f\"\\n=== Naive Bayes (Multinomial) + {representation_name} — alpha sweep ===\")\n",
        "    for a in alphas:\n",
        "        model = MultinomialNB(alpha=a)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "        acc, f1 = evaluate_scores(y_val, y_pred)\n",
        "        results.append({\"alpha\": a, \"accuracy\": acc, \"f1_macro\": f1})\n",
        "        print(f\"alpha = {a:>4}  ->  Accuracy = {acc:.4f},  Macro F1 = {f1:.4f}\")\n",
        "    # Print best by F1\n",
        "    best = max(results, key=lambda r: r[\"f1_macro\"])\n",
        "    print(f\"\\nBest alpha by macro F1: {best['alpha']} (Accuracy={best['accuracy']:.4f}, F1={best['f1_macro']:.4f})\")\n",
        "    return results\n",
        "\n",
        "\n",
        "def tune_logistic(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    X_val,\n",
        "    y_val,\n",
        "    Cs,\n",
        "    max_iter=1000,\n",
        "    representation_name=\"TF-IDF\",\n",
        "    model_name_suffix=\"\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Hyperparameter tuning for Logistic Regression on arbitrary features\n",
        "    (TF-IDF or Word2Vec).\n",
        "    Varies the regularization strength C and prints validation performance.\n",
        "    Returns a list of results (C, accuracy, f1).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    print(f\"\\n=== Logistic Regression {model_name_suffix} + {representation_name} — C sweep (max_iter={max_iter}) ===\")\n",
        "    for c in Cs:\n",
        "        clf = LogisticRegression(C=c, max_iter=max_iter)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_val)\n",
        "        acc, f1 = evaluate_scores(y_val, y_pred)\n",
        "        results.append({\"C\": c, \"accuracy\": acc, \"f1_macro\": f1})\n",
        "        print(f\"C = {c:>5}  ->  Accuracy = {acc:.4f},  Macro F1 = {f1:.4f}\")\n",
        "    # Print best by F1\n",
        "    best = max(results, key=lambda r: r[\"f1_macro\"])\n",
        "    print(f\"\\nBest C by macro F1: {best['C']} (Accuracy={best['accuracy']:.4f}, F1={best['f1_macro']:.4f})\")\n",
        "    return results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NSL6hdnX910h",
        "outputId": "4946b19c-d475-4f02-ff12-8a2b32ee4bc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NSL6hdnX910h",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Naive Bayes (Multinomial) + TF-IDF (multi-class) — alpha sweep ===\n",
            "alpha =  0.1  ->  Accuracy = 0.6283,  Macro F1 = 0.3005\n",
            "alpha =  0.5  ->  Accuracy = 0.6311,  Macro F1 = 0.2910\n",
            "alpha =  1.0  ->  Accuracy = 0.6324,  Macro F1 = 0.2822\n",
            "\n",
            "Best alpha by macro F1: 0.1 (Accuracy=0.6283, F1=0.3005)\n",
            "\n",
            "=== Logistic Regression  + TF-IDF (multi-class) — C sweep (max_iter=2000) ===\n",
            "C =   0.1  ->  Accuracy = 0.6389,  Macro F1 = 0.3151\n",
            "C =   1.0  ->  Accuracy = 0.6435,  Macro F1 = 0.3895\n",
            "C =  10.0  ->  Accuracy = 0.6149,  Macro F1 = 0.4249\n",
            "\n",
            "Best C by macro F1: 10.0 (Accuracy=0.6149, F1=0.4249)\n",
            "\n",
            "=== Logistic Regression  + Word2Vec (multi-class) — C sweep (max_iter=2000) ===\n",
            "C =   0.1  ->  Accuracy = 0.6275,  Macro F1 = 0.2696\n",
            "C =   1.0  ->  Accuracy = 0.6274,  Macro F1 = 0.2779\n",
            "C =  10.0  ->  Accuracy = 0.6273,  Macro F1 = 0.2785\n",
            "\n",
            "Best C by macro F1: 10.0 (Accuracy=0.6273, F1=0.2785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **תזכורת:**"
      ],
      "metadata": {
        "id": "krPxzvEhA9OL"
      },
      "id": "krPxzvEhA9OL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✔ Accuracy (דיוק)\n",
        "כמה אחוז מהניבואים של המודל היו נכונים מתוך כלל הדוגמאות.\n",
        "\n",
        "**איך להבין את זה?**  \n",
        "אם המודל ניחש נכון 70% מהפעמים → Accuracy = 0.70\n",
        "\n",
        "**מתי זה טוב?**  \n",
        "כאשר הדאטה מאוזן*\n",
        "(כל המחלקות מופיעות בערך באותה כמות).\n",
        "\n",
        "**החיסרון:**  \n",
        "אם מחלקה אחת מופיעה הרבה יותר – המדד עלול להיות מטעה.\n",
        "\n",
        "---\n",
        "\n",
        "### ✔ F1 Score (מדד F1)\n",
        "מדד שמחבר בין\n",
        " Precision ו־Recall\n",
        "  למדד אחד מאוזן.\n",
        "\n",
        "**איך להבין את זה?**  \n",
        " גבוה = המודל גם מוצא נכון דוגמאות של המחלקה וגם לא טועה הרבה.  \n",
        " נמוך = או שהמודל מפספס הרבה דוגמאות, או שהוא טועה הרבה.\n",
        "\n",
        "**מתי משתמשים בו?**  \n",
        "כאשר חשוב לזהות כל מחלקה בצורה טובה במיוחד,\n",
        "או כאשר יש אי־איזון בין המחלקות.\n",
        "\n",
        "---\n",
        "\n",
        "### ✔ Macro F1 (מדד F1 מאקרו)\n",
        "מחשב את ה\n",
        "F1\n",
        " לכל מחלקה בנפרד, ואז עושה ממוצע פשוט ביניהן.\n",
        "\n",
        "**איך להבין את זה?**  \n",
        "כל מחלקה מקבלת משקל שווה — גם אם יש ממנה מעט דוגמאות.\n",
        "\n",
        "**למה זה חשוב?**  \n",
        "כי בבעיות שבהן חלק מהמחלקות מופיעות מעט ,  \n",
        "Accuracy\n",
        " יכול להטעות,\n",
        "אבל\n",
        "Macro F1\n",
        "מוודא שהמודל מצליח גם על המחלקות הקטנות.\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "XKxwMcfsBAUN"
      },
      "id": "XKxwMcfsBAUN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ניסויים בהיפר פרמטרים***"
      ],
      "metadata": {
        "id": "dDp0khU2_rSd"
      },
      "id": "dDp0khU2_rSd"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Additional Hyperparameter Experiments\n",
        "# ============================================\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 1) Naive Bayes + TF-IDF with more alpha values\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "nb_alphas_extended = [0.01, 0.1, 0.5, 1.0, 2.0]\n",
        "nb_tfidf_results_extended = tune_nb_tfidf(\n",
        "    X_train_tfidf_multi,\n",
        "    y_train_multi,\n",
        "    X_val_tfidf_multi,\n",
        "    y_val_multi,\n",
        "    alphas=nb_alphas_extended,\n",
        "    representation_name=\"TF-IDF (multi-class) — extended alpha\"\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 2) Logistic Regression + TF-IDF with extended C values\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "lr_C_extended = [0.01, 0.1, 1.0, 10.0, 50.0, 100.0]\n",
        "lr_tfidf_results_extended = tune_logistic(\n",
        "    X_train_tfidf_multi,\n",
        "    y_train_multi,\n",
        "    X_val_tfidf_multi,\n",
        "    y_val_multi,\n",
        "    Cs=lr_C_extended,\n",
        "    max_iter=3000,  # slightly higher, helps convergence\n",
        "    representation_name=\"TF-IDF (multi-class) — extended C\",\n",
        "    model_name_suffix=\"\"\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 3) Logistic Regression + TF-IDF — small max_iter test\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "lr_tfidf_small_iter = tune_logistic(\n",
        "    X_train_tfidf_multi,\n",
        "    y_train_multi,\n",
        "    X_val_tfidf_multi,\n",
        "    y_val_multi,\n",
        "    Cs=[1.0],\n",
        "    max_iter=200,  # very small to force non-convergence\n",
        "    representation_name=\"TF-IDF (multi-class) — small max_iter\",\n",
        "    model_name_suffix=\"\"\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 4) Logistic Regression + TF-IDF — large max_iter test\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "lr_tfidf_large_iter = tune_logistic(\n",
        "    X_train_tfidf_multi,\n",
        "    y_train_multi,\n",
        "    X_val_tfidf_multi,\n",
        "    y_val_multi,\n",
        "    Cs=[1.0],\n",
        "    max_iter=5000,  # large enough to guarantee convergence\n",
        "    representation_name=\"TF-IDF (multi-class) — large max_iter\",\n",
        "    model_name_suffix=\"\"\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 5) Logistic Regression + Word2Vec — extended C values\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "lr_w2v_extended = tune_logistic(\n",
        "    X_train_w2v_multi,\n",
        "    y_train_multi,\n",
        "    X_val_w2v_multi,\n",
        "    y_val_multi,\n",
        "    Cs=lr_C_extended,\n",
        "    max_iter=3000,\n",
        "    representation_name=\"Word2Vec (multi-class) — extended C\",\n",
        "    model_name_suffix=\"\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "-FpUkxNY_uvG",
        "outputId": "291aac0a-45dd-4cc8-f836-16b17e8d164c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-FpUkxNY_uvG",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Naive Bayes (Multinomial) + TF-IDF (multi-class) — extended alpha — alpha sweep ===\n",
            "alpha = 0.01  ->  Accuracy = 0.6277,  Macro F1 = 0.3025\n",
            "alpha =  0.1  ->  Accuracy = 0.6283,  Macro F1 = 0.3005\n",
            "alpha =  0.5  ->  Accuracy = 0.6311,  Macro F1 = 0.2910\n",
            "alpha =  1.0  ->  Accuracy = 0.6324,  Macro F1 = 0.2822\n",
            "alpha =  2.0  ->  Accuracy = 0.6330,  Macro F1 = 0.2763\n",
            "\n",
            "Best alpha by macro F1: 0.01 (Accuracy=0.6277, F1=0.3025)\n",
            "\n",
            "=== Logistic Regression  + TF-IDF (multi-class) — extended C — C sweep (max_iter=3000) ===\n",
            "C =  0.01  ->  Accuracy = 0.6280,  Macro F1 = 0.2572\n",
            "C =   0.1  ->  Accuracy = 0.6389,  Macro F1 = 0.3151\n",
            "C =   1.0  ->  Accuracy = 0.6435,  Macro F1 = 0.3895\n",
            "C =  10.0  ->  Accuracy = 0.6149,  Macro F1 = 0.4249\n",
            "C =  50.0  ->  Accuracy = 0.5998,  Macro F1 = 0.4276\n",
            "C = 100.0  ->  Accuracy = 0.5991,  Macro F1 = 0.4280\n",
            "\n",
            "Best C by macro F1: 100.0 (Accuracy=0.5991, F1=0.4280)\n",
            "\n",
            "=== Logistic Regression  + TF-IDF (multi-class) — small max_iter — C sweep (max_iter=200) ===\n",
            "C =   1.0  ->  Accuracy = 0.6435,  Macro F1 = 0.3895\n",
            "\n",
            "Best C by macro F1: 1.0 (Accuracy=0.6435, F1=0.3895)\n",
            "\n",
            "=== Logistic Regression  + TF-IDF (multi-class) — large max_iter — C sweep (max_iter=5000) ===\n",
            "C =   1.0  ->  Accuracy = 0.6435,  Macro F1 = 0.3895\n",
            "\n",
            "Best C by macro F1: 1.0 (Accuracy=0.6435, F1=0.3895)\n",
            "\n",
            "=== Logistic Regression  + Word2Vec (multi-class) — extended C — C sweep (max_iter=3000) ===\n",
            "C =  0.01  ->  Accuracy = 0.6279,  Macro F1 = 0.2598\n",
            "C =   0.1  ->  Accuracy = 0.6275,  Macro F1 = 0.2696\n",
            "C =   1.0  ->  Accuracy = 0.6274,  Macro F1 = 0.2779\n",
            "C =  10.0  ->  Accuracy = 0.6273,  Macro F1 = 0.2785\n",
            "C =  50.0  ->  Accuracy = 0.6274,  Macro F1 = 0.2777\n",
            "C = 100.0  ->  Accuracy = 0.6275,  Macro F1 = 0.2782\n",
            "\n",
            "Best C by macro F1: 10.0 (Accuracy=0.6273, F1=0.2785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***עד לפה זה החדש =========================================================================================================================================================================================================***"
      ],
      "metadata": {
        "id": "sIysXP7YjYPj"
      },
      "id": "sIysXP7YjYPj"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}