{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "8baca3dd-ec1a-4dee-bc5b-aa9e48680865",
      "metadata": {
        "id": "8baca3dd-ec1a-4dee-bc5b-aa9e48680865",
        "outputId": "4067fb3f-81fb-479e-b93c-188bb48aff28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NLP Text Processing Pipeline (20k subset) ===\n",
            "Python: 3.12.12 | Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "Run started at: 2025-11-16T15:33:52\n"
          ]
        }
      ],
      "source": [
        "#ROI ğŸ“˜ ×ª× â€œ×”×•×›×—×ª ×¨×™×¦×”â€ + ×§×•× ×¤×™×’×•×¨×¦×™×” ×‘×¡×™×¡×™×ª (×ª××™×“ ×™×“×¤×™×¡ ×—×•×ª××ª-×–××Ÿ)\n",
        "import sys, platform, datetime\n",
        "print(\"=== NLP Text Processing Pipeline (20k subset) ===\")\n",
        "print(\"Python:\", sys.version.split()[0], \"| Platform:\", platform.platform())\n",
        "print(\"Run started at:\", datetime.datetime.now().isoformat(timespec='seconds'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "9ff5669d-2694-4447-ae63-2f03c12be22a",
      "metadata": {
        "id": "9ff5669d-2694-4447-ae63-2f03c12be22a",
        "outputId": "ec999ee9-ab4b-4210-fb40-9e30f5b239d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK resources are ready.\n"
          ]
        }
      ],
      "source": [
        "# ×ª× 1 â€” ×˜×¢×™× ×ª ×¡×¤×¨×™×•×ª ×•××©××‘×™ NLTK\n",
        "# ğŸ“˜ ×˜×¢×™× ×ª ×¡×¤×¨×™×•×ª ×•××©××‘×™ NLTK (×™×•×¨×™×“×• ××•×˜×•××˜×™×ª ×× ×—×¡×¨×™×)\n",
        "import pandas as pd\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "\n",
        "print(\"NLTK resources are ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "b8b8f3a3-2f14-42ee-91e9-6aafd64e94ab",
      "metadata": {
        "id": "b8b8f3a3-2f14-42ee-91e9-6aafd64e94ab",
        "outputId": "80277288-050d-48fd-91d9-cc8ea826e864",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from: /content/train.xls\n",
            "Loaded rows: 90425\n",
            "ID column: id\n",
            "Text columns to process: ['question', 'context', 'answer', 'level', 'type', 'quotes']\n"
          ]
        }
      ],
      "source": [
        "# ×ª× 2 â€” ×˜×¢×™× ×ª ×”Ö¾Dataset, ×–×™×”×•×™ ×¢××•×“×ª ID ×•×¢××•×“×•×ª ×˜×§×¡×˜\n",
        "# ğŸ“˜ ×˜×¢×™× ×ª ×”×“××˜×”, ×–×™×”×•×™ ×¢××•×“×ª ×”-ID (×× ×§×™×™××ª), ×•×–×™×”×•×™ ×¢××•×“×•×ª ×˜×§×¡×˜ (object) ×œ×¢×™×‘×•×“\n",
        "DATA_PATH = \"/content/train.xls\"\n",
        "print(f\"Loading dataset from: {DATA_PATH}\")\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Loaded rows:\", len(df))\n",
        "\n",
        "# ×–×™×”×•×™ ×¢××•×“×ª ID\n",
        "id_candidates = ['id', 'Id', 'ID']\n",
        "ID_COL = next((c for c in id_candidates if c in df.columns), None)\n",
        "print(\"ID column:\", ID_COL if ID_COL else \"None\")\n",
        "\n",
        "# ×¢××•×“×•×ª ×˜×§×¡×˜ (×›×œ ×¢××•×“×” ××¡×•×’ object ×—×•×¥ ××”-ID)\n",
        "text_cols = [c for c in df.columns if df[c].dtype == 'object' and c != ID_COL]\n",
        "print(\"Text columns to process:\", text_cols if text_cols else \"None\")\n",
        "if not text_cols:\n",
        "    raise ValueError(\"No text columns found to process.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "87597e0d-4fea-4e30-b344-6084d73c5766",
      "metadata": {
        "id": "87597e0d-4fea-4e30-b344-6084d73c5766",
        "outputId": "61615417-150b-405b-da16-0ac1e101fd0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering rows to keep only those with at least one non-empty text column...\n",
            "Rows after non-empty filter: 20000\n",
            "Rows capped at 500: 500\n"
          ]
        }
      ],
      "source": [
        "# ×ª× 3 â€” ×¡×™× ×•×Ÿ ×©×•×¨×•×ª ×œ× ×¨×™×§×•×ª ×•×‘×—×™×¨×” ×‘Ö¾20,000 ×©×•×¨×•×ª\n",
        "# ğŸ“˜ ×©××™×¨×” ×¢×œ ×©×•×¨×•×ª ×©×‘×”×Ÿ ×œ×¤×—×•×ª ××—×ª ××¢××•×“×•×ª ×”×˜×§×¡×˜ ××™× ×” ×¨×™×§×”/×¨×™×§×”-××—×¨×™-strip\n",
        "def non_empty_any(row):\n",
        "    for c in text_cols:\n",
        "        v = row[c]\n",
        "        if isinstance(v, str) and v.strip():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "print(\"Filtering rows to keep only those with at least one non-empty text column...\")\n",
        "mask = df.apply(non_empty_any, axis=1)\n",
        "df = df[mask]\n",
        "\n",
        "print(\"Rows after non-empty filter:\", len(df))\n",
        "df = df.head(500)  # ×‘×—×™×¨×” ×‘Ö¾20,000 ×©×•×¨×•×ª ×”×¨××©×•× ×•×ª\n",
        "print(\"Rows capped at 500:\", len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfUnprossed = df.copy()\n"
      ],
      "metadata": {
        "id": "zyhBLrFSU4-l"
      },
      "id": "zyhBLrFSU4-l",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "f75c3ea9-2602-433b-9934-cccac5f026ff",
      "metadata": {
        "id": "f75c3ea9-2602-433b-9934-cccac5f026ff"
      },
      "outputs": [],
      "source": [
        "# ×ª× 4 â€” ×¤×•× ×§×¦×™×•×ª ×¢×™×‘×•×“: × ×™×§×•×™, Lemmatization ×¢× POS, ×•×”×•×¦××ª Stopwords\n",
        "# ğŸ“˜ ×¤×•× ×§×¦×™×•×ª ×¢×™×‘×•×“ ×˜×§×¡×˜ ×œ×›×œ ×¢××•×“×” ×‘× ×¤×¨×“:\n",
        "#    - ×”×¡×¨×ª URL/Email/Handles\n",
        "#    - ×˜×•×§× ×™×–×¦×™×”\n",
        "#    - POS tagging + Lemmatization (×¢× ××™×¤×•×™ ×œ-WordNet)\n",
        "#    - ×“×™×œ×•×’ ×¢×œ ×©××•×ª ×¤×¨×˜×™×™× (NNP/NNPS)\n",
        "#    - × ×¨××•×œ ×¦×•×¨×•×ª 'be' (am/is/are/was/were/been/being -> be)\n",
        "#    - ×”×—×œ×¤×ª ×¡×¤×¨×•×ª ×‘-_number\n",
        "#    - ×”×¡×¨×ª ×ª×•×•×™× ×©××™× × ××•×ª×™×•×ª ×œ×˜×™× ×™×•×ª/underscore/×¨×•×•×—\n",
        "#    - ×”×¡×¨×ª stopwords\n",
        "#    - ×”×•×¨×“×ª ×¨×™×©×™×•×ª\n",
        "#\n",
        "# ×”×¢×¨×”: ×œ× × ×•×¦×¨×™× ×¢××•×“×•×ª ×—×“×©×•×ª â€” ×”×¤×•× ×§×¦×™×” ×ª×—×–×™×¨ ××—×¨×•×–×ª ××¢×•×‘×“×ª ×©×ª×—×œ×™×£ ××ª ×ª×•×›×Ÿ ×”×¢××•×“×”.\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "eng_stops = set(stopwords.words('english'))\n",
        "BE_FORMS = {\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\"}\n",
        "\n",
        "def get_wordnet_pos(tag: str):\n",
        "    if tag.startswith('J'): return wordnet.ADJ\n",
        "    if tag.startswith('V'): return wordnet.VERB\n",
        "    if tag.startswith('N'): return wordnet.NOUN\n",
        "    if tag.startswith('R'): return wordnet.ADV\n",
        "    return wordnet.NOUN\n",
        "\n",
        "url_email_handle_re = re.compile(r'(https?://\\S+|www\\.\\S+|\\S+@\\S+|[@#]\\w+)', re.IGNORECASE)\n",
        "digits_re = re.compile(r'\\d+')           # ×¡×¤×¨×•×ª -> _number\n",
        "non_letter_re = re.compile(r'[^a-z_ ]+') # ××—×¨×™ lowercase, × ×©××™×¨ a-z, ×¨×•×•×—, underscore\n",
        "\n",
        "def process_text_value(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    t = text\n",
        "\n",
        "    # ×”×¡×¨×” ×¨××©×•× ×™×ª ×©×œ URL/Emails/Handles/Hashtags ×›×“×™ ×œ× ×œ×”×¨×•×¡ POS\n",
        "    t = url_email_handle_re.sub(' ', t)\n",
        "\n",
        "    # ×˜×•×§× ×™×–×¦×™×” + POS ×¢×œ ×”×˜×§×¡×˜ ×”××§×•×¨×™ (×œ×¤× ×™ lowercase) ×œ×˜×•×‘×ª Proper Nouns ×˜×•×‘ ×™×•×ª×¨\n",
        "    tokens = word_tokenize(t)\n",
        "    tagged = pos_tag(tokens)\n",
        "\n",
        "    # Lemmatization ×¢× POS + ×“×™×œ×•×’ ×¢×œ Proper Nouns + × ×¨××•×œ 'be'\n",
        "    lemmas = []\n",
        "    for tok, pos in tagged:\n",
        "        # × ×¨××•×œ ××•×§×“× ×œ-be\n",
        "        if tok.lower() in BE_FORMS:\n",
        "            lemmas.append(\"be\")\n",
        "            continue\n",
        "        if pos in (\"NNP\", \"NNPS\"):   # ×”×©××¨×ª ×©××•×ª ×¤×¨×˜×™×™× ×›××• ×©×”×\n",
        "            lemmas.append(tok)\n",
        "            continue\n",
        "        wn_pos = get_wordnet_pos(pos)\n",
        "        lemmas.append(lemmatizer.lemmatize(tok, wn_pos))\n",
        "\n",
        "    # lowercase\n",
        "    lemmas = [w.lower() for w in lemmas]\n",
        "\n",
        "    # ×”×—×œ×¤×ª ×¡×¤×¨×•×ª ×œ-_number (×¢×œ ×˜×•×§× ×™×)\n",
        "    lemmas = [digits_re.sub('_number', w) for w in lemmas]\n",
        "\n",
        "    # ×©××™×¨×” ×¨×§ ×¢×œ a-z/_/×¨×•×•×— â€” × ×¡× ×Ÿ ×˜×•×§× ×™× ×©×œ× ×¢×•××“×™× ×‘×–×”\n",
        "    clean_lemmas = []\n",
        "    for w in lemmas:\n",
        "        w2 = non_letter_re.sub(' ', w).strip()\n",
        "        if not w2:\n",
        "            continue\n",
        "        # ×™×™×ª×›×Ÿ ×©× ×•×¦×¨×• ×¨×•×•×—×™×; × ×™×§×— ××ª ×”\"×˜×•×§×Ÿ\" ×”×¨××©×•×Ÿ (××• × ×¤×¨×§ ×œ×¨×‘×™×)\n",
        "        for part in w2.split():\n",
        "            clean_lemmas.append(part)\n",
        "\n",
        "    # ×”×•×¦××ª stopwords\n",
        "    clean_lemmas = [w for w in clean_lemmas if w not in eng_stops]\n",
        "\n",
        "    # ×—×™×‘×•×¨ ×—×–×¨×” ×œ××—×¨×•×–×ª\n",
        "    return \" \".join(clean_lemmas)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54f1486b"
      },
      "source": [
        "eng_stops = set(stopwords.words('english'))\n",
        "\n",
        "def process_text_value_partial(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Lowercase\n",
        "    tokens = [w.lower() for w in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    clean_tokens = [w for w in tokens if w not in eng_stops]\n",
        "\n",
        "    # Join back to string\n",
        "    return \" \".join(clean_tokens)"
      ],
      "id": "54f1486b",
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "b6c972ec",
        "outputId": "d04df411-c98b-4daa-dc82-03168c549101"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "def get_tokenized_sentences(dataframe, text_columns):\n",
        "    all_tokenized_sentences = []\n",
        "    for col in text_columns:\n",
        "        for text_value in dataframe[col].dropna():\n",
        "            if isinstance(text_value, str):\n",
        "                all_tokenized_sentences.append(word_tokenize(text_value))\n",
        "    return all_tokenized_sentences\n",
        "\n",
        "# Define X_WORDS_TO_DISPLAY for this cell\n",
        "X_WORDS_TO_DISPLAY = 2000 # You can change this value\n",
        "\n",
        "print(\"Tokenizing dfUnprossed...\")\n",
        "tokenized_sentences_unprocessed = get_tokenized_sentences(dfUnprossed, text_cols)\n",
        "print(f\"Generated {len(tokenized_sentences_unprocessed)} tokenized sentences from dfUnprossed.\")\n",
        "\n",
        "print(\"\\nTokenizing df_out...\")\n",
        "tokenized_sentences_processed = get_tokenized_sentences(df_out, text_cols)\n",
        "print(f\"Generated {len(tokenized_sentences_processed)} tokenized sentences from df_out.\")\n",
        "\n",
        "print(\"\\nFirst 3 tokenized sentences from dfUnprossed (example):\")\n",
        "for i, s in enumerate(tokenized_sentences_unprocessed[:3]):\n",
        "    print(f\"  {i+1}: {s}\")\n",
        "\n",
        "print(\"\\nFirst 3 tokenized sentences from df_out (example):\")\n",
        "for i, s in enumerate(tokenized_sentences_processed[:3]):\n",
        "    print(f\"  {i+1}: {s}\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Calculating and displaying top words for df_out ---\n",
        "print(\"\\nCalculating top words for df_out...\")\n",
        "all_tokens_processed = [token for sentence in tokenized_sentences_processed for token in sentence] # Flatten list of lists\n",
        "token_counts_processed = Counter(all_tokens_processed)\n",
        "top_x_words_processed = token_counts_processed.most_common(X_WORDS_TO_DISPLAY)\n",
        "df_top_words_processed = pd.DataFrame(top_x_words_processed, columns=['Word', 'Frequency'])\n",
        "print(f\"Top {X_WORDS_TO_DISPLAY} words from df_out:\")\n",
        "display(df_top_words_processed)"
      ],
      "id": "b6c972ec",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing dfUnprossed...\n",
            "Generated 3000 tokenized sentences from dfUnprossed.\n",
            "\n",
            "Tokenizing df_out...\n",
            "Generated 3000 tokenized sentences from df_out.\n",
            "\n",
            "First 3 tokenized sentences from dfUnprossed (example):\n",
            "  1: ['magazine', 'started', 'first', 'arthur', \"'s\", 'magazine', 'first', 'women', '?']\n",
            "  2: ['oberoi', 'family', 'part', 'hotel', 'company', 'head', 'office', 'city', '?']\n",
            "  3: ['musician', 'satirist', 'allie', 'goertz', 'wrote', 'song', '``', 'simpsons', '``', 'character', 'milhouse', ',', 'matt', 'groening', 'named', '?']\n",
            "\n",
            "First 3 tokenized sentences from df_out (example):\n",
            "  1: ['magazine', 'start', 'first', 'arthur', 'magazine', 'first', 'women']\n",
            "  2: ['oberoi', 'family', 'part', 'hotel', 'company', 'head', 'office', 'city']\n",
            "  3: ['musician', 'satirist', 'allie', 'goertz', 'write', 'song', 'simpsons', 'character', 'milhouse', 'matt', 'groening', 'name']\n",
            "\n",
            "Calculating top words for df_out...\n",
            "Top 2000 words from df_out:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          Word  Frequency\n",
              "0      _number      21712\n",
              "1         film       2391\n",
              "2     american       1925\n",
              "3        first       1525\n",
              "4        album       1488\n",
              "...        ...        ...\n",
              "1995   jenkins         25\n",
              "1996       mel         25\n",
              "1997     pizza         25\n",
              "1998     kroll         25\n",
              "1999      kirk         25\n",
              "\n",
              "[2000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85f29ee9-f7a2-4b66-8ffc-71ef232569d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_number</td>\n",
              "      <td>21712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>film</td>\n",
              "      <td>2391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>american</td>\n",
              "      <td>1925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>first</td>\n",
              "      <td>1525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>album</td>\n",
              "      <td>1488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>jenkins</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>mel</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>pizza</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>kroll</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>kirk</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85f29ee9-f7a2-4b66-8ffc-71ef232569d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85f29ee9-f7a2-4b66-8ffc-71ef232569d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85f29ee9-f7a2-4b66-8ffc-71ef232569d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-94e2bb18-cd38-4b1a-8d93-3ac19ed4864f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94e2bb18-cd38-4b1a-8d93-3ac19ed4864f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-94e2bb18-cd38-4b1a-8d93-3ac19ed4864f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5108aed2-cc59-4899-b7c8-fe45b1f2303c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_top_words_processed')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5108aed2-cc59-4899-b7c8-fe45b1f2303c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_top_words_processed');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_top_words_processed",
              "summary": "{\n  \"name\": \"df_top_words_processed\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"device\",\n          \"pop\",\n          \"personal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frequency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 508,\n        \"min\": 25,\n        \"max\": 21712,\n        \"num_unique_values\": 328,\n        \"samples\": [\n          121,\n          299,\n          102\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "652a8306-090b-4343-bc63-cef14329582a",
      "metadata": {
        "id": "652a8306-090b-4343-bc63-cef14329582a",
        "outputId": "4e978b16-c1bf-46b5-f798-819e84756926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing text columns independently (no new columns will be added)...\n",
            "Processing column: question\n",
            "Processing column: context\n",
            "Processing column: answer\n",
            "Processing column: level\n",
            "Processing column: type\n",
            "Processing column: quotes\n",
            "All text columns processed.\n"
          ]
        }
      ],
      "source": [
        "# ×ª× 5 â€” ×¢×™×‘×•×“ ×›×œ ×¢××•×“×•×ª ×”×˜×§×¡×˜ (×œ×œ× ×™×¦×™×¨×ª ×¢××•×“×•×ª ×—×“×©×•×ª)\n",
        "# ğŸ“˜ ×¢×™×‘×•×“ ×›×œ ×¢××•×“×•×ª ×”×˜×§×¡×˜ ×‘× ×¤×¨×“ ×•×”×—×œ×¤×ª ×”×ª×•×›×Ÿ ×‘×˜×§×¡×˜ ×”××¢×•×‘×“.\n",
        "print(\"Processing text columns independently (no new columns will be added)...\")\n",
        "\n",
        "df_out = df.copy()\n",
        "for c in text_cols:\n",
        "    print(f\"Processing column: {c}\")\n",
        "    df_out[c] = df_out[c].apply(process_text_value)\n",
        "\n",
        "print(\"All text columns processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for c in text_cols:\n",
        "    print(f\"Processing column: {c}\")\n",
        "    dfUnprossed[c] = dfUnprossed[c].apply(process_text_value_partial)\n",
        "\n",
        "print(\"All text columns processed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nI3eNSCYNBt",
        "outputId": "8bd77380-2833-49b7-9e91-d1d24deacaa2"
      },
      "id": "3nI3eNSCYNBt",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing column: question\n",
            "Processing column: context\n",
            "Processing column: answer\n",
            "Processing column: level\n",
            "Processing column: type\n",
            "Processing column: quotes\n",
            "All text columns processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdb76c09-b5d2-4773-b329-fbece680d4fb",
      "metadata": {
        "id": "bdb76c09-b5d2-4773-b329-fbece680d4fb"
      },
      "outputs": [],
      "source": [
        "# ×ª× 6 â€” ×©××™×¨×” ×œÖ¾CSV ×—×“×© (××•×ª×” ×¡×›×™××”, ×˜×§×¡×˜×™× ××—×¨×™ ×¢×™×‘×•×“)\n",
        "# ğŸ“˜ ×©××™×¨×” ×œ-CSV ×—×“×© ×¢× ××•×ª×Ÿ ×¢××•×“×•×ª; ×¢××•×“×•×ª ×”×˜×§×¡×˜ ×›×‘×¨ ×”×•×—×œ×¤×• ×‘×’×¨×¡×” ×œ××—×¨ ×”×¢×™×‘×•×“.\n",
        "OUT_PATH = Path(\"hotpotqa_csv/processed_train_20k.csv\")\n",
        "df_out.to_csv(OUT_PATH, index=False, encoding='utf-8')\n",
        "print(f\"Processed CSV saved to: {OUT_PATH.resolve()}\")\n",
        "print(\"Done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ae8d869-4c52-4bb6-9ab6-823c6efadbd6",
      "metadata": {
        "id": "9ae8d869-4c52-4bb6-9ab6-823c6efadbd6"
      },
      "outputs": [],
      "source": [
        "# ×ª× 7 â€” ×‘×“×™×§×ª Before/After ××”×™×¨×” (×¢×œ ×¢××•×“×ª ×˜×§×¡×˜ ××—×ª ×œ×“×•×’××”)\n",
        "# ğŸ“˜ ×”×“×’××ª Before/After ××”×™×¨×” (×œ×¦×•×¨×›×™ ××™××•×ª) â€” ×œ× ×™×•×¦×¨×ª ×¢××•×“×•×ª ×—×“×©×•×ª\n",
        "# × ×‘×—×¨ ××ª ×”×¢××•×“×” ×”×˜×§×¡×˜×•××œ×™×ª ×”×¨××©×•× ×” ×•×”×“×¤×¡×” ×©×œ 2 ×“×•×’×××•×ª\n",
        "demo_col = text_cols[0]\n",
        "print(f\"Demo on column: {demo_col}\")\n",
        "\n",
        "orig_samples = df[demo_col].head(2).tolist()\n",
        "proc_samples = df_out[demo_col].head(2).tolist()\n",
        "\n",
        "for i, (orig, proc) in enumerate(zip(orig_samples, proc_samples), start=1):\n",
        "    print(f\"\\nğŸ”¸ Example {i}\")\n",
        "    print(\"Before:\", str(orig)[:200])\n",
        "    print(\"After: \", str(proc)[:200])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9888323a-9cb4-44c9-809b-a34787e0ca1a",
      "metadata": {
        "id": "9888323a-9cb4-44c9-809b-a34787e0ca1a"
      },
      "outputs": [],
      "source": [
        "# ×ª× â€“ Exploratory & Visual Statistics\n",
        "# ğŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª ×•×™×–×•××œ×™×•×ª ×•× ×™×ª×•×— ×¨××©×•× ×™ ×¢×œ ×”×“××˜×” ×œ××—×¨ ×”×¢×™×‘×•×“\n",
        "# ------------------------------------------------------------\n",
        "# ×›×•×œ×œ:\n",
        "# 1. ×’×¨×£ ×”×ª×¤×œ×’×•×ª ×§×˜×’×•×¨×™×•×ª ×›×œ×œ×™×•×ª (labels)\n",
        "# 2. ×’×¨×£ ××™×•×—×“ ×œ×¢××•×“×ª 'level'\n",
        "# 3. ×”×™×¡×˜×•×’×¨××ª ××•×¨×š ×˜×§×¡×˜×™×\n",
        "# 4. ×¨×©×™××ª ××™×œ×™× ×•×‘×™×˜×•×™×™× ×©×›×™×—×™× (unigrams/bigrams)\n",
        "# 5. ×˜×‘×œ×ª ×¡×™×›×•× ×©×œ×‘×™×\n",
        "# 6. ×“×•×’×××•×ª ××™×›×•×ª ×œ×¤×™ ×§×˜×’×•×¨×™×”\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "\n",
        "plt.rcParams.update({'axes.unicode_minus': False})\n",
        "\n",
        "# -----------------------------------\n",
        "# 1. ×’×¨×£ ×”×ª×¤×œ×’×•×ª ×§×˜×’×•×¨×™×•×ª ×›×œ×œ×™×•×ª\n",
        "# -----------------------------------\n",
        "print(\"ğŸ”¹ Checking for categorical (label) columns...\")\n",
        "candidate_labels = ['label','category','topic','type','sentiment','class','answer']\n",
        "label_col = next((c for c in candidate_labels if c in df_out.columns and df_out[c].notna().any()), None)\n",
        "\n",
        "if label_col:\n",
        "    print(f\"Label column detected: {label_col}\")\n",
        "    label_counts = df_out[label_col].astype(str).value_counts()\n",
        "    print(\"\\nTop categories:\")\n",
        "    print(label_counts.head(10))\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    label_counts.plot(kind='bar', color='cornflowerblue')\n",
        "    plt.title(f\"Category Distribution â€“ {label_col}\")\n",
        "    plt.xlabel(\"Category\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No generic label column detected â€” skipping label distribution plot.\")\n",
        "\n",
        "# -----------------------------------\n",
        "# 2. ×’×¨×£ ×œ×¢××•×“×ª LEVEL\n",
        "# -----------------------------------\n",
        "if 'level' in df_out.columns:\n",
        "    print(\"\\nğŸ”¹ Found 'level' column â€“ displaying its distribution...\")\n",
        "\n",
        "    level_counts = df_out['level'].astype(str).value_counts()\n",
        "    print(level_counts.head(10))\n",
        "\n",
        "    # ×’×¨×£ ×¢××•×“×•×ª\n",
        "    plt.figure(figsize=(8,4))\n",
        "    level_counts.plot(kind='bar', color='mediumseagreen')\n",
        "    plt.title(\"Distribution of LEVEL categories\")\n",
        "    plt.xlabel(\"Level\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ×’×¨×£ ×¢×•×’×” (×× ×™×© ×œ× ×™×•×ª×¨ ××“×™ ×§×˜×’×•×¨×™×•×ª)\n",
        "    if len(level_counts) <= 10:\n",
        "        plt.figure(figsize=(6,6))\n",
        "        plt.pie(level_counts.values, labels=level_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "        plt.title(\"LEVEL category distribution (Pie chart)\")\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"\\nNo 'level' column found â€” skipping LEVEL charts.\")\n",
        "\n",
        "# -----------------------------------\n",
        "# 3. ×”×™×¡×˜×•×’×¨××ª ××•×¨×š ×˜×§×¡×˜×™×\n",
        "# -----------------------------------\n",
        "print(\"\\nğŸ”¹ Text length histogram (in tokens):\")\n",
        "\n",
        "def count_tokens(text):\n",
        "    if not isinstance(text, str):\n",
        "        return 0\n",
        "    return len(text.split())\n",
        "\n",
        "text_col = next((c for c in df_out.columns if c not in ['id','Id','ID','level',label_col] and df_out[c].dtype=='object'), None)\n",
        "if text_col:\n",
        "    df_out['text_length'] = df_out[text_col].apply(count_tokens)\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.hist(df_out['text_length'], bins=30, color='lightblue', edgecolor='black')\n",
        "    plt.title(f\"Histogram of text lengths ({text_col})\")\n",
        "    plt.xlabel(\"Number of tokens\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Average length:\", round(df_out['text_length'].mean(),2))\n",
        "    print(\"Median length:\", round(df_out['text_length'].median(),2))\n",
        "else:\n",
        "    print(\"No text column detected for histogram.\")\n",
        "\n",
        "# -----------------------------------\n",
        "# 4. ×¨×©×™××ª ××™×œ×™× ×•×‘×™×˜×•×™×™× ×©×›×™×—×™×\n",
        "# -----------------------------------\n",
        "print(\"\\nğŸ”¹ Most frequent tokens and bigrams:\")\n",
        "tokens = []\n",
        "for c in df_out.columns:\n",
        "    if df_out[c].dtype == 'object' and c not in [label_col,'level']:\n",
        "        for text in df_out[c].dropna():\n",
        "            tokens.extend(text.split())\n",
        "\n",
        "token_counts = Counter(tokens)\n",
        "top_tokens = token_counts.most_common(20)\n",
        "print(\"\\nTop 20 tokens:\")\n",
        "for w, f in top_tokens:\n",
        "    print(f\"{w:<15} {f}\")\n",
        "\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "bigram_counts = Counter(bigrams)\n",
        "top_bigrams = bigram_counts.most_common(10)\n",
        "print(\"\\nTop 10 bigrams:\")\n",
        "for (a,b), f in top_bigrams:\n",
        "    print(f\"{a} {b:<15} {f}\")\n",
        "\n",
        "# -----------------------------------\n",
        "# 5. ×˜×‘×œ×ª ×¡×™×›×•× × ×™×§×•×™ (×× ×§×™×™××ª)\n",
        "# -----------------------------------\n",
        "print(\"\\nğŸ”¹ Cleaning summary table (estimated):\")\n",
        "try:\n",
        "    summary\n",
        "    display(summary)\n",
        "except NameError:\n",
        "    print(\"(No detailed step metrics found in current notebook scope.)\")\n",
        "    print(f\"Current dataset size: {len(df_out)} rows\")\n",
        "\n",
        "# -----------------------------------\n",
        "# 6. ×“×•×’×××•×ª ××™×›×•×ª ×œ×¤×™ ×§×˜×’×•×¨×™×”\n",
        "# -----------------------------------\n",
        "print(\"\\nğŸ”¹ Sample examples per category:\")\n",
        "target_col = label_col or ('level' if 'level' in df_out.columns else None)\n",
        "if target_col:\n",
        "    for cat in df_out[target_col].astype(str).unique()[:5]:  # ×¢×“ 5 ×§×˜×’×•×¨×™×•×ª\n",
        "        print(f\"\\nCategory: {cat}\")\n",
        "        samples = df_out[df_out[target_col].astype(str) == cat][text_col].dropna().head(2)\n",
        "        for i, s in enumerate(samples, start=1):\n",
        "            print(f\" Example {i}: {s[:250]}\")\n",
        "else:\n",
        "    print(\"No label or level column available for examples.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3bcad4-e41c-467d-a064-fddf45b21087",
      "metadata": {
        "id": "ce3bcad4-e41c-467d-a064-fddf45b21087"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}